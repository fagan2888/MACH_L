{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ON MY COMPUTER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name:  Tom Bresee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### University of Michigan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ad6923a92962cdba6be891fcf161e328",
     "grade": false,
     "grade_id": "cell-632b4c666041719a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"v1.6.083120\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Side Comments:_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One common pattern within machine learning is to use linear models trained on nonlinear functions of the data. This approach maintains the generally fast performance of linear methods, while allowing them to fit a much wider range of data.\n",
    "* Polynomial features are those features created by raising existing features to an exponent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6fe05db1aa234f334babc8331b3fd36c",
     "grade": false,
     "grade_id": "cell-c712284a9739c04e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 2: Regression and Classification\n",
    "\n",
    "In this assignment we will build several regression and classification models and learn how model complexity relates to generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c3a7680d16f10c8ef49662ad86955f0c",
     "grade": false,
     "grade_id": "cell-8576d03826e617fe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "First, run the following cell to generate and plot the data points we will use throughout the assignment. \n",
    "\n",
    "The independent variable $x$ consists of 40 evenly spaced points from the interval $[0, 20]$ and the dependent variable $y = 0.05x^3 - x^2 - x + 10 \\epsilon$ is a function of $x$ where $\\epsilon \\sim \\mathcal{N}(0, 1)$ represents the standard Gaussian noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b0157f6869833c7f131bbe1525d53eab",
     "grade": false,
     "grade_id": "cell-91d5b2819b0753ea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(0)\n",
    "n = 40\n",
    "x = np.linspace(0, 20, n)  # x is drawn from a fixed range\n",
    "y = x ** 3 / 20 - x ** 2 - x + 10 * np.random.randn(n)\n",
    "\n",
    "\n",
    "# Create the training and testing sets and their targets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-----------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#-----------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.51282051,  1.02564103,  1.53846154,  2.05128205,\n",
       "        2.56410256,  3.07692308,  3.58974359,  4.1025641 ,  4.61538462,\n",
       "        5.12820513,  5.64102564,  6.15384615,  6.66666667,  7.17948718,\n",
       "        7.69230769,  8.20512821,  8.71794872,  9.23076923,  9.74358974,\n",
       "       10.25641026, 10.76923077, 11.28205128, 11.79487179, 12.30769231,\n",
       "       12.82051282, 13.33333333, 13.84615385, 14.35897436, 14.87179487,\n",
       "       15.38461538, 15.8974359 , 16.41025641, 16.92307692, 17.43589744,\n",
       "       17.94871795, 18.46153846, 18.97435897, 19.48717949, 20.        ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 17.64052346,   3.23250989,   7.76374492,  18.685673  ,\n",
       "        12.84810472, -18.06860307,  -1.58696289, -15.67665642,\n",
       "       -18.51326541, -16.89538048, -23.24305524, -13.94425898,\n",
       "       -24.76103832, -35.07954613, -35.7825447 , -40.76885527,\n",
       "       -32.96831091, -53.64280973, -51.98083869, -66.97046565,\n",
       "       -87.03464369, -57.76058237, -58.12075543, -76.29098381,\n",
       "       -47.87141143, -86.36718715, -72.13500742, -74.70752353,\n",
       "       -57.18455635, -56.88853607, -68.4550774 , -63.95754775,\n",
       "       -73.62338589, -80.79112354, -59.89072654, -49.4269181 ,\n",
       "       -32.37620107, -25.41344759, -33.09763136, -23.02302751])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.84615385, 17.94871795, 18.97435897,  1.02564103, 20.        ,\n",
       "       15.38461538, 17.43589744,  8.20512821, 18.46153846,  4.1025641 ,\n",
       "        6.66666667,  2.56410256,  8.71794872,  7.17948718, 16.92307692,\n",
       "        3.58974359, 16.41025641,  0.51282051, 13.33333333,  6.15384615,\n",
       "       15.8974359 , 12.30769231,  3.07692308, 11.79487179, 10.76923077,\n",
       "        9.74358974,  4.61538462, 19.48717949,  1.53846154,  0.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-74.70752353, -49.4269181 , -25.41344759,   7.76374492,\n",
       "       -23.02302751, -68.4550774 , -59.89072654, -32.96831091,\n",
       "       -32.37620107, -18.51326541, -35.07954613, -18.06860307,\n",
       "       -53.64280973, -35.7825447 , -80.79112354, -15.67665642,\n",
       "       -73.62338589,   3.23250989, -72.13500742, -24.76103832,\n",
       "       -63.95754775, -47.87141143,  -1.58696289, -76.29098381,\n",
       "       -57.76058237, -66.97046565, -16.89538048, -33.09763136,\n",
       "        18.685673  ,  17.64052346])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def data_scatter():\n",
    "    \n",
    "    \"\"\"\n",
    "    This function helps you visualize the training and testing sets by drawing a scatter plot of the data points.\n",
    "    Feel free to change the function in any ways to create your own visuals. \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(X_train, y_train, label='training')\n",
    "    plt.scatter(X_test, y_test, label='testing')\n",
    "    plt.legend(loc=4)\n",
    "\n",
    "    \n",
    "# Remember to comment it out before submitting the notebook\n",
    "data_scatter()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6cbcb74528ebdb4553e3560b84bb97ae",
     "grade": false,
     "grade_id": "cell-446072eaa6bc03b9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 1. (15 pts)\n",
    "\n",
    "From the data generation process we can see that a *linear* function is not sufficient to accurately describe the relationship between $x$ and $y$. What we really need is a *non-linear* regression that relates $x$ and $y$ in a non-linear way, which in our case we conjecture $y$ is a *polynomial* function of various degrees of $x$:\n",
    "\n",
    "\\begin{equation*}\n",
    "y = a_{0} + a_{1}x + a_{2}x^{2} + \\cdots + a_{n}x^{n}\n",
    "\\end{equation*}\n",
    "\n",
    "where $a_{0}, a_{1}, \\cdots, a_{n}$ are the coefficients we want to find. Notice that although $y$ is not a linear function of $x$, it is linear in each power of $x$. That means we can still run linear regression, but now on powers of $x$ instead of the zeroth and the first power of $x$ only. To do so we need to create various powers of $x$ out of the data we have now using the [`PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn-preprocessing-polynomialfeatures) class from `scikit-learn`. \n",
    "\n",
    "Write a function that fits a polynomial [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) model on the *training data* `X_train` for degrees 1, 3, 7, 11, 15, 21, respectively. To do this, first use `PolynomialFeatures` to transform the original data so that it adds new additional polynomial features. With this expanded feature set, fit a `LinearRegression` model. For each model, generate predictions for 100 evenly spaced points on the interval [0, 20] and store the results in a numpy array, whose the first row stores the predictions from the model of degree 1, the second row stores the predictions from the model of degree 3 and so on. \n",
    "\n",
    "*This function should return a numpy array of the shape `(6, 100)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the values should be horizontal (6 total) of 100 values each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(poly deg 3) linear model coeff (w):\n",
      "[ 0.         -3.20680908 -0.84053006  0.0460391 ]\n",
      "(poly deg 3) linear model intercept (b): 11.359\n",
      "(poly deg 3) R-squared score (training): 0.904\n",
      "(poly deg 3) R-squared score (test): 0.809\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-38c15365affc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0manswer_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-38c15365affc>\u001b[0m in \u001b[0;36manswer_one\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mX_predict_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m# print(X_predict_input)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "# TEMP:\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "degs = (1, 3, 7, 11, 15, 21)  # this will be useful later\n",
    "\n",
    "\n",
    "def answer_one():\n",
    "    \n",
    "    preds = None\n",
    "    \n",
    "    spread = np.linspace(0,20, num=100)\n",
    "\n",
    "    # --- my code here ---\n",
    "    \n",
    "    # We will need to transform the original input data to add polynomial features \n",
    "    # up to degree 21 (degrees 1,3,7,11,15,21)\n",
    "    \n",
    "    poly = PolynomialFeatures(degree=3)\n",
    "    \n",
    "    x_poly = poly.fit_transform(x.reshape(-1,1))\n",
    "    \n",
    "    # print(x_poly)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_poly, y, random_state=0)\n",
    "\n",
    "    linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    print('(poly deg 3) linear model coeff (w):\\n{}'.format(linreg.coef_))\n",
    "\n",
    "\n",
    "    print('(poly deg 3) linear model intercept (b): {:.3f}'.format(linreg.intercept_))\n",
    "\n",
    "\n",
    "    print('(poly deg 3) R-squared score (training): {:.3f}'.format(linreg.score(X_train, y_train)))\n",
    " \n",
    "\n",
    "    print('(poly deg 3) R-squared score (test): {:.3f}\\n'.format(linreg.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "    X_predict_input = np.linspace(0,20, num=100)\n",
    "    \n",
    "    # print(X_predict_input)\n",
    "    \n",
    "    first_preds = linreg.predict(X_predict_input)\n",
    "\n",
    "    print(first_preds)\n",
    "    \n",
    "    # return preds\n",
    "    \n",
    "\n",
    "answer_one()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- print(x_poly) ---\n",
    "#     \n",
    "# [[1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
    "#  [1.00000000e+00 5.12820513e-01 2.62984878e-01 1.34864040e-01]\n",
    "#  [1.00000000e+00 1.02564103e+00 1.05193951e+00 1.07891232e+00]\n",
    "#  [1.00000000e+00 1.53846154e+00 2.36686391e+00 3.64132909e+00]\n",
    "#  [1.00000000e+00 2.05128205e+00 4.20775805e+00 8.63129857e+00]\n",
    "#  [1.00000000e+00 2.56410256e+00 6.57462196e+00 1.68580050e+01]\n",
    "#  [1.00000000e+00 3.07692308e+00 9.46745562e+00 2.91306327e+01]\n",
    "#  [1.00000000e+00 3.58974359e+00 1.28862590e+01 4.62583658e+01]\n",
    "#  [1.00000000e+00 4.10256410e+00 1.68310322e+01 6.90503886e+01]\n",
    "#  [1.00000000e+00 4.61538462e+00 2.13017751e+01 9.83158853e+01]\n",
    "#  [1.00000000e+00 5.12820513e+00 2.62984878e+01 1.34864040e+02]\n",
    "#  [1.00000000e+00 5.64102564e+00 3.18211703e+01 1.79504037e+02]\n",
    "#  [1.00000000e+00 6.15384615e+00 3.78698225e+01 2.33045061e+02]\n",
    "#  [1.00000000e+00 6.66666667e+00 4.44444444e+01 2.96296296e+02]\n",
    "#  [1.00000000e+00 7.17948718e+00 5.15450362e+01 3.70066926e+02]\n",
    "#  [1.00000000e+00 7.69230769e+00 5.91715976e+01 4.55166136e+02]\n",
    "#  [1.00000000e+00 8.20512821e+00 6.73241289e+01 5.52403109e+02]\n",
    "#  [1.00000000e+00 8.71794872e+00 7.60026298e+01 6.62587029e+02]\n",
    "#  [1.00000000e+00 9.23076923e+00 8.52071006e+01 7.86527082e+02]\n",
    "#  [1.00000000e+00 9.74358974e+00 9.49375411e+01 9.25032452e+02]\n",
    "#  [1.00000000e+00 1.02564103e+01 1.05193951e+02 1.07891232e+03]\n",
    "#  [1.00000000e+00 1.07692308e+01 1.15976331e+02 1.24897588e+03]\n",
    "#  [1.00000000e+00 1.12820513e+01 1.27284681e+02 1.43603230e+03]\n",
    "#  [1.00000000e+00 1.17948718e+01 1.39119001e+02 1.64089078e+03]\n",
    "#  [1.00000000e+00 1.23076923e+01 1.51479290e+02 1.86436049e+03]\n",
    "#  [1.00000000e+00 1.28205128e+01 1.64365549e+02 2.10725063e+03]\n",
    "#  [1.00000000e+00 1.33333333e+01 1.77777778e+02 2.37037037e+03]\n",
    "#  [1.00000000e+00 1.38461538e+01 1.91715976e+02 2.65452890e+03]\n",
    "#  [1.00000000e+00 1.43589744e+01 2.06180145e+02 2.96053541e+03]\n",
    "#  [1.00000000e+00 1.48717949e+01 2.21170283e+02 3.28919908e+03]\n",
    "#  [1.00000000e+00 1.53846154e+01 2.36686391e+02 3.64132909e+03]\n",
    "#  [1.00000000e+00 1.58974359e+01 2.52728468e+02 4.01773462e+03]\n",
    "#  [1.00000000e+00 1.64102564e+01 2.69296515e+02 4.41922487e+03]\n",
    "#  [1.00000000e+00 1.69230769e+01 2.86390533e+02 4.84660901e+03]\n",
    "#  [1.00000000e+00 1.74358974e+01 3.04010519e+02 5.30069624e+03]\n",
    "#  [1.00000000e+00 1.79487179e+01 3.22156476e+02 5.78229572e+03]\n",
    "#  [1.00000000e+00 1.84615385e+01 3.40828402e+02 6.29221666e+03]\n",
    "#  [1.00000000e+00 1.89743590e+01 3.60026298e+02 6.83126823e+03]\n",
    "#  [1.00000000e+00 1.94871795e+01 3.79750164e+02 7.40025961e+03]\n",
    "#  [1.00000000e+00 2.00000000e+01 4.00000000e+02 8.00000000e+03]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3cc2530b7f9ac349c7a833c9ee03942a",
     "grade": false,
     "grade_id": "cell-9d09d1cc72cefb51",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # FINAL \n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# degs = (1, 3, 7, 11, 15, 21)  # this will be useful later\n",
    "\n",
    "\n",
    "\n",
    "# def answer_one():\n",
    "    \n",
    "#     preds = None\n",
    "\n",
    "#     # --- my code here ---\n",
    "    \n",
    "#     # We will need to transform the original input data to add polynomial features \n",
    "#     # up to degree 21 (degrees 1,3,7,11,15,21)\n",
    "    \n",
    "#     poly = PolynomialFeatures(degree=3)\n",
    "    \n",
    "#     X_poly = poly.fit_transform(X)\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state=0)\n",
    "\n",
    "#     linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "\n",
    "#     print('(poly deg 3) linear model coeff (w):\\n{}'\n",
    "#      .format(linreg.coef_))\n",
    "\n",
    "\n",
    "#     print('(poly deg 3) linear model intercept (b): {:.3f}'\n",
    "#      .format(linreg.intercept_))\n",
    "\n",
    "\n",
    "#     print('(poly deg 3) R-squared score (training): {:.3f}'\n",
    "#      .format(linreg.score(X_train, y_train)))\n",
    "\n",
    "\n",
    "#     print('(poly deg 3) R-squared score (test): {:.3f}\\n'\n",
    "#      .format(linreg.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "#     return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "56b59de705d8601061f9a1b7aee6fcc4",
     "grade": true,
     "grade_id": "cell-958d3ffafa45b8c3",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(poly deg 3) linear model coeff (w):\n",
      "[ 0.         -3.20680908 -0.84053006  0.0460391 ]\n",
      "(poly deg 3) linear model intercept (b): 11.359\n",
      "(poly deg 3) R-squared score (training): 0.904\n",
      "(poly deg 3) R-squared score (test): 0.809\n",
      "\n",
      "[ 0.          0.2020202   0.4040404   0.60606061  0.80808081  1.01010101\n",
      "  1.21212121  1.41414141  1.61616162  1.81818182  2.02020202  2.22222222\n",
      "  2.42424242  2.62626263  2.82828283  3.03030303  3.23232323  3.43434343\n",
      "  3.63636364  3.83838384  4.04040404  4.24242424  4.44444444  4.64646465\n",
      "  4.84848485  5.05050505  5.25252525  5.45454545  5.65656566  5.85858586\n",
      "  6.06060606  6.26262626  6.46464646  6.66666667  6.86868687  7.07070707\n",
      "  7.27272727  7.47474747  7.67676768  7.87878788  8.08080808  8.28282828\n",
      "  8.48484848  8.68686869  8.88888889  9.09090909  9.29292929  9.49494949\n",
      "  9.6969697   9.8989899  10.1010101  10.3030303  10.50505051 10.70707071\n",
      " 10.90909091 11.11111111 11.31313131 11.51515152 11.71717172 11.91919192\n",
      " 12.12121212 12.32323232 12.52525253 12.72727273 12.92929293 13.13131313\n",
      " 13.33333333 13.53535354 13.73737374 13.93939394 14.14141414 14.34343434\n",
      " 14.54545455 14.74747475 14.94949495 15.15151515 15.35353535 15.55555556\n",
      " 15.75757576 15.95959596 16.16161616 16.36363636 16.56565657 16.76767677\n",
      " 16.96969697 17.17171717 17.37373737 17.57575758 17.77777778 17.97979798\n",
      " 18.18181818 18.38383838 18.58585859 18.78787879 18.98989899 19.19191919\n",
      " 19.39393939 19.5959596  19.7979798  20.        ]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.          0.2020202   0.4040404   0.60606061  0.80808081  1.01010101\n  1.21212121  1.41414141  1.61616162  1.81818182  2.02020202  2.22222222\n  2.42424242  2.62626263  2.82828283  3.03030303  3.23232323  3.43434343\n  3.63636364  3.83838384  4.04040404  4.24242424  4.44444444  4.64646465\n  4.84848485  5.05050505  5.25252525  5.45454545  5.65656566  5.85858586\n  6.06060606  6.26262626  6.46464646  6.66666667  6.86868687  7.07070707\n  7.27272727  7.47474747  7.67676768  7.87878788  8.08080808  8.28282828\n  8.48484848  8.68686869  8.88888889  9.09090909  9.29292929  9.49494949\n  9.6969697   9.8989899  10.1010101  10.3030303  10.50505051 10.70707071\n 10.90909091 11.11111111 11.31313131 11.51515152 11.71717172 11.91919192\n 12.12121212 12.32323232 12.52525253 12.72727273 12.92929293 13.13131313\n 13.33333333 13.53535354 13.73737374 13.93939394 14.14141414 14.34343434\n 14.54545455 14.74747475 14.94949495 15.15151515 15.35353535 15.55555556\n 15.75757576 15.95959596 16.16161616 16.36363636 16.56565657 16.76767677\n 16.96969697 17.17171717 17.37373737 17.57575758 17.77777778 17.97979798\n 18.18181818 18.38383838 18.58585859 18.78787879 18.98989899 19.19191919\n 19.39393939 19.5959596  19.7979798  20.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e24d65f07be0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Autograder tests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstu_ans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manswer_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstu_ans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Q1: Your function should return a np.ndarray. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-7d2a30f035cc>\u001b[0m in \u001b[0;36manswer_one\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_predict_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mfirst_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_predict_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m    220\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    620\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.          0.2020202   0.4040404   0.60606061  0.80808081  1.01010101\n  1.21212121  1.41414141  1.61616162  1.81818182  2.02020202  2.22222222\n  2.42424242  2.62626263  2.82828283  3.03030303  3.23232323  3.43434343\n  3.63636364  3.83838384  4.04040404  4.24242424  4.44444444  4.64646465\n  4.84848485  5.05050505  5.25252525  5.45454545  5.65656566  5.85858586\n  6.06060606  6.26262626  6.46464646  6.66666667  6.86868687  7.07070707\n  7.27272727  7.47474747  7.67676768  7.87878788  8.08080808  8.28282828\n  8.48484848  8.68686869  8.88888889  9.09090909  9.29292929  9.49494949\n  9.6969697   9.8989899  10.1010101  10.3030303  10.50505051 10.70707071\n 10.90909091 11.11111111 11.31313131 11.51515152 11.71717172 11.91919192\n 12.12121212 12.32323232 12.52525253 12.72727273 12.92929293 13.13131313\n 13.33333333 13.53535354 13.73737374 13.93939394 14.14141414 14.34343434\n 14.54545455 14.74747475 14.94949495 15.15151515 15.35353535 15.55555556\n 15.75757576 15.95959596 16.16161616 16.36363636 16.56565657 16.76767677\n 16.96969697 17.17171717 17.37373737 17.57575758 17.77777778 17.97979798\n 18.18181818 18.38383838 18.58585859 18.78787879 18.98989899 19.19191919\n 19.39393939 19.5959596  19.7979798  20.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_one()\n",
    "\n",
    "assert isinstance(stu_ans, np.ndarray), \"Q1: Your function should return a np.ndarray. \"\n",
    "assert stu_ans.shape == (6, 100), \"Q1: Your np.ndarray is of an incorrect shape. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(poly deg 3) linear model coeff (w):\n",
      "[ 0.         -3.20680908 -0.84053006  0.0460391 ]\n",
      "(poly deg 3) linear model intercept (b): 11.359\n",
      "(poly deg 3) R-squared score (training): 0.904\n",
      "(poly deg 3) R-squared score (test): 0.809\n",
      "\n",
      "[ 0.          0.2020202   0.4040404   0.60606061  0.80808081  1.01010101\n",
      "  1.21212121  1.41414141  1.61616162  1.81818182  2.02020202  2.22222222\n",
      "  2.42424242  2.62626263  2.82828283  3.03030303  3.23232323  3.43434343\n",
      "  3.63636364  3.83838384  4.04040404  4.24242424  4.44444444  4.64646465\n",
      "  4.84848485  5.05050505  5.25252525  5.45454545  5.65656566  5.85858586\n",
      "  6.06060606  6.26262626  6.46464646  6.66666667  6.86868687  7.07070707\n",
      "  7.27272727  7.47474747  7.67676768  7.87878788  8.08080808  8.28282828\n",
      "  8.48484848  8.68686869  8.88888889  9.09090909  9.29292929  9.49494949\n",
      "  9.6969697   9.8989899  10.1010101  10.3030303  10.50505051 10.70707071\n",
      " 10.90909091 11.11111111 11.31313131 11.51515152 11.71717172 11.91919192\n",
      " 12.12121212 12.32323232 12.52525253 12.72727273 12.92929293 13.13131313\n",
      " 13.33333333 13.53535354 13.73737374 13.93939394 14.14141414 14.34343434\n",
      " 14.54545455 14.74747475 14.94949495 15.15151515 15.35353535 15.55555556\n",
      " 15.75757576 15.95959596 16.16161616 16.36363636 16.56565657 16.76767677\n",
      " 16.96969697 17.17171717 17.37373737 17.57575758 17.77777778 17.97979798\n",
      " 18.18181818 18.38383838 18.58585859 18.78787879 18.98989899 19.19191919\n",
      " 19.39393939 19.5959596  19.7979798  20.        ]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.          0.2020202   0.4040404   0.60606061  0.80808081  1.01010101\n  1.21212121  1.41414141  1.61616162  1.81818182  2.02020202  2.22222222\n  2.42424242  2.62626263  2.82828283  3.03030303  3.23232323  3.43434343\n  3.63636364  3.83838384  4.04040404  4.24242424  4.44444444  4.64646465\n  4.84848485  5.05050505  5.25252525  5.45454545  5.65656566  5.85858586\n  6.06060606  6.26262626  6.46464646  6.66666667  6.86868687  7.07070707\n  7.27272727  7.47474747  7.67676768  7.87878788  8.08080808  8.28282828\n  8.48484848  8.68686869  8.88888889  9.09090909  9.29292929  9.49494949\n  9.6969697   9.8989899  10.1010101  10.3030303  10.50505051 10.70707071\n 10.90909091 11.11111111 11.31313131 11.51515152 11.71717172 11.91919192\n 12.12121212 12.32323232 12.52525253 12.72727273 12.92929293 13.13131313\n 13.33333333 13.53535354 13.73737374 13.93939394 14.14141414 14.34343434\n 14.54545455 14.74747475 14.94949495 15.15151515 15.35353535 15.55555556\n 15.75757576 15.95959596 16.16161616 16.36363636 16.56565657 16.76767677\n 16.96969697 17.17171717 17.37373737 17.57575758 17.77777778 17.97979798\n 18.18181818 18.38383838 18.58585859 18.78787879 18.98989899 19.19191919\n 19.39393939 19.5959596  19.7979798  20.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0854fc6f6abd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Remember to comment it out before submitting the notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mplot_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-7d2a30f035cc>\u001b[0m in \u001b[0;36manswer_one\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_predict_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mfirst_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_predict_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m    220\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    620\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.          0.2020202   0.4040404   0.60606061  0.80808081  1.01010101\n  1.21212121  1.41414141  1.61616162  1.81818182  2.02020202  2.22222222\n  2.42424242  2.62626263  2.82828283  3.03030303  3.23232323  3.43434343\n  3.63636364  3.83838384  4.04040404  4.24242424  4.44444444  4.64646465\n  4.84848485  5.05050505  5.25252525  5.45454545  5.65656566  5.85858586\n  6.06060606  6.26262626  6.46464646  6.66666667  6.86868687  7.07070707\n  7.27272727  7.47474747  7.67676768  7.87878788  8.08080808  8.28282828\n  8.48484848  8.68686869  8.88888889  9.09090909  9.29292929  9.49494949\n  9.6969697   9.8989899  10.1010101  10.3030303  10.50505051 10.70707071\n 10.90909091 11.11111111 11.31313131 11.51515152 11.71717172 11.91919192\n 12.12121212 12.32323232 12.52525253 12.72727273 12.92929293 13.13131313\n 13.33333333 13.53535354 13.73737374 13.93939394 14.14141414 14.34343434\n 14.54545455 14.74747475 14.94949495 15.15151515 15.35353535 15.55555556\n 15.75757576 15.95959596 16.16161616 16.36363636 16.56565657 16.76767677\n 16.96969697 17.17171717 17.37373737 17.57575758 17.77777778 17.97979798\n 18.18181818 18.38383838 18.58585859 18.78787879 18.98989899 19.19191919\n 19.39393939 19.5959596  19.7979798  20.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "\n",
    "# Optional: Now let's plot the polynomials we learned from the training data, along with the training and the testing data\n",
    "# Feel free to change this function in any way to create your own visuals. \n",
    "\n",
    "degs = (1, 3, 7, 11, 15, 21)\n",
    "\n",
    "def plot_one(predictions):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(X_train, y_train, 'o', label='training', markersize=10)\n",
    "    plt.plot(X_test, y_test, 'o', label='testing', markersize=10)\n",
    "    for i, deg in enumerate(degs):\n",
    "        plt.plot(np.linspace(0, 20, 100), predictions[i], alpha=0.8, lw=2, label=f\"degree={deg}\")\n",
    "    plt.legend(loc=4)\n",
    "\n",
    "# Remember to comment it out before submitting the notebook\n",
    "plot_one(answer_one())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d686283b69e5c2d24e67b4dfaad68539",
     "grade": false,
     "grade_id": "cell-e03d061d866f4ce3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 2. (15 pts)\n",
    "\n",
    "Write a function that fits a polynomial LinearRegression model on the training data `X_train` for degrees = (1, 3, 7, 11, 15, 21). For each model compute the $R^2$ (coefficient of determination) regression score on the training data as well as the the testing data. \n",
    "\n",
    "*This function should return a tuple of lists `(r2_train, r2_test)`, where `r2_train` contains the $R^{2}$ scores on the training data and the other contains the $R^{2}$ scores on the testing data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7af0b14c6c3a4f77f241870a98ec9501",
     "grade": false,
     "grade_id": "cell-8e79274985200c84",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics.regression import r2_score\n",
    "\n",
    "degs = (1, 3, 7, 11, 15, 21)  # this will be useful later\n",
    "\n",
    "def answer_two():\n",
    "    r2_train, r2_test = None, None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return r2_train, r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8dbd4a4fe90c0c7f716543238ccce0a8",
     "grade": true,
     "grade_id": "cell-bb110de000a7e0bb",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e320e20e2c5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Autograder tests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstu_ans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manswer_two\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstu_ans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Q2: Your function should return a tuple. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstu_ans\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Q2: The tuple returned should be of length 2. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-20c4f6c35529>\u001b[0m in \u001b[0;36manswer_two\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr2_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_two()\n",
    "assert isinstance(stu_ans, tuple), \"Q2: Your function should return a tuple. \"\n",
    "assert len(stu_ans) == 2, \"Q2: The tuple returned should be of length 2. \"\n",
    "assert isinstance(stu_ans[0], list) and isinstance(stu_ans[1], list), \"Q2: The tuple should contain only lists. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7ac940a3a5cff4cc240e7b619f76ffe0",
     "grade": false,
     "grade_id": "cell-5fd99b5e42526782",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 3. (5 pts)\n",
    "\n",
    "Fit a k-NN regression model with the training data and return the $R^{2}$ value on the testing data. Use the default hyper-parameters. \n",
    "\n",
    "*This function should return a single `float` number.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c90445fe3250946def610189b93b21ef",
     "grade": false,
     "grade_id": "cell-b972f6f246770ec7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def answer_three():\n",
    "    r2 = None\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "625a235e154e0466353fd1fd3538029b",
     "grade": true,
     "grade_id": "cell-8011dc023a29b90f",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-20a6cebe044a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Autograder tests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstu_ans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manswer_three\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstu_ans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Q3: Your function should return a single float number. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-bb8893cb1f2f>\u001b[0m in \u001b[0;36manswer_three\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_three()\n",
    "\n",
    "assert isinstance(stu_ans, float), \"Q3: Your function should return a single float number. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5d8d690328e41afdc0293a6bd272aadd",
     "grade": false,
     "grade_id": "cell-3084a88cc1b74788",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 4a.  (5 pts)\n",
    "\n",
    "Based on the $R^2$ scores from Question 2, which degree of the polynomial causes the model to be\n",
    " - underfitting; \n",
    " - overfitting; or\n",
    " - achieving good generalisation performance? \n",
    "\n",
    "Hint: Try to plot the degrees of the polynomial against the $R^2$ scores to visualise their relationship. \n",
    "\n",
    "*This is a manually graded question. Write down your answer in the cell below following the order `(Underfitting, Overfitting, Good_Generalisation)`, where you will replace the words with the actual degrees, for example, (1, 2, 3). There might be multiple correct answers, but you only need to write down ONE.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "496a1432d5aa678204ecf0b1f58c568f",
     "grade": true,
     "grade_id": "cell-cc7057f082f79066",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Your answer goes here\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cf35ff5f924f9fb8bcf7687ee1af2e22",
     "grade": false,
     "grade_id": "cell-8081bbbdc902974d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 4b. (15 pts) \n",
    "\n",
    "Training models on high-degree polynomial features can result in overly complex models that overfit the training data, so we often add some regularization to constrain the model complexity as we saw in Ridge and Lasso regression.\n",
    "\n",
    "For this question, you will be comparing the non-regularized `LinearRegression` model (with the default hyper-parameters) that you built for Question 1, to a new regularised Lasso Regression model (with hyper-parameters `alpha=0.01`, `max_iter=10000`) --- on polynomial features of varying degrees, so you can see the difference with the polynomials that were fit in Question 1.\n",
    "\n",
    "Your function should return predictions for the regularized model in the same format that you used for question 1: namely, you generate predictions for 100 evenly spaced points on the interval [0, 20] and store the results in a numpy array, whose the first row stores the predictions from the model of degree 1, the second row stores the predictions from the model of degree 3 and so on.\n",
    "\n",
    "*This function should return a numpy array of the shape `(6, 100)`.*\n",
    "\n",
    "Once you have successful generated these predictions, plot them using the provided function and compare with the polynomial fit in Question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "979c705ff43442b49cf9476fbbf75076",
     "grade": false,
     "grade_id": "cell-7c7af5bcec432359",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.metrics.regression import r2_score\n",
    "\n",
    "degs = (1, 3, 7, 11, 15, 21)\n",
    "def answer_four_b():\n",
    "    preds = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d5b1efb41a6035984bee313c26c25670",
     "grade": true,
     "grade_id": "cell-10a959987014433e",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-7480f68a4095>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Autograder tests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstu_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_four_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstu_ans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Q4b: Your function should return a np.ndarray. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-171e9f8bb5f7>\u001b[0m in \u001b[0;36manswer_four_b\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_four_b()\n",
    "\n",
    "assert isinstance(stu_ans, np.ndarray), \"Q4b: Your function should return a np.ndarray. \"\n",
    "assert stu_ans.shape == (6, 100), \"Q4b: Your np.ndarray is of an incorrect shape: it should be (6, 100).\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to comment it out before submitting the notebook\n",
    "# plot_one(answer_four_b())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bfee738e32cd73698d434cdbc4e98d1f",
     "grade": false,
     "grade_id": "cell-03113efdb52e1650",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 4c. (15 points) \n",
    "\n",
    "Return the $R^2$ score for the Lasso model relative to a test set generated from the true underlying model.  Compute this test set by computing the true underlying function `t^3/20 - t^2 - t` for each of 100 evenly spaced points on the interval [0, 20] (the same as you've used in previous questions).  For each degree (1, 3, 7, 11, 15, 21), compute the $R^2$ score and return the polynomial degree that gives the best fit on this test set. Your function should return an integer, which should be in the set (1,3,7,11,15,21).  Does the optimal polynomial degree match the true polynomial degree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f25a7bf73ba17676652a103b8b0dcae8",
     "grade": false,
     "grade_id": "cell-b5394665d22fb09e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "degs = (1, 3, 7, 11, 15, 21)\n",
    "\n",
    "def answer_four_c():\n",
    "    best_deg = []\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return best_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b58a4adb8f826d1074d2ac57113c740",
     "grade": true,
     "grade_id": "cell-21481cca025d7fe5",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stu_ans = answer_four_c()\n",
    "\n",
    "assert isinstance(stu_ans, int), \"Q4c: Your function should return an integer. \"\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e0647ff645f6e320c4b65007262abe75",
     "grade": false,
     "grade_id": "cell-650ff1903c708769",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 5. Comparison of results (5 points)\n",
    "\n",
    "Compare the test set $R^2$ results of the Lasso regression and polynomial regression above. Did the regularization have the desired effect?  Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "722a462d5b2c292a1777d7dd20dfd91f",
     "grade": true,
     "grade_id": "cell-7031a79d535c2f2f",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Your answer goes here\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6. Ridge vs Lasso regularization (5 points)\n",
    "\n",
    "We didn't happen to try Ridge regression on this example - but it also does regularization. Would you expect Ridge regression to consistently outperform Lasso regression on this particular regression task? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "70b4442511245ccc560cbb9484bacc75",
     "grade": true,
     "grade_id": "cell-91d7f112aa2ecffb",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Your answer goes here\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a1530dea484bbdc29d9299bb0b690db0",
     "grade": false,
     "grade_id": "cell-722b305be5dccb0f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 7.  (15 points)  Applying a SVC classifier to the Wisconsin dataset\n",
    "\n",
    "We're going to return to the Wisconsin breast cancer dataset to apply our newly learned Support Vector classifier  (`SVC`).\n",
    "\n",
    "For this question, we're also going to use the `validation_curve` function in `sklearn.model_selection` to determine training and test scores for the Support Vector Classifier with varying parameter values.\n",
    "\n",
    "Create an `SVC` with default parameters (i.e. `kernel='rbf', C=1`) and `random_state=0`. Recall that the kernel width of the RBF kernel is controlled using the `gamma` parameter.  Explore the effect of `gamma` on classifier accuracy by using the `validation_curve` function to find the training and test scores for 6 values of `gamma` from `1e-7` to `1e-2` (i.e. `np.logspace(-7,-1,6)`, or more precisely `[1.e-07, 1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02]`).\n",
    "\n",
    "For each level of `gamma`, `validation_curve` will fit 3 models on different subsets of the data, returning two 6x3 (6 levels of gamma x 3 fits per level) arrays of the scores for the training and test sets. \n",
    "\n",
    "Find the mean score across the three models for each level of `gamma` for both arrays, creating two arrays of length 6, and return a tuple with the two arrays.\n",
    "\n",
    "e.g.\n",
    "\n",
    "if one of your array of scores is\n",
    "\n",
    "    array([[ 0.5,  0.4,  0.6],\n",
    "           [ 0.7,  0.8,  0.7],\n",
    "           [ 0.9,  0.8,  0.8],\n",
    "           [ 0.8,  0.7,  0.8],\n",
    "           [ 0.7,  0.6,  0.6],\n",
    "           [ 0.4,  0.6,  0.5]])\n",
    "       \n",
    "it should then become\n",
    "\n",
    "    array([ 0.5,  0.73333333,  0.83333333,  0.76666667,  0.63333333, 0.5])\n",
    "\n",
    "*This function should return a tuple of numpy arrays `(training_scores, test_scores)` where each array in the tuple has shape `(6,)`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a74c3ac047d170ef0a9d02b5c33dc08b",
     "grade": false,
     "grade_id": "cell-2244bfa56f789d18",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Here's the preliminary code to load the dataset and prepare the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "data      = np.hstack([cancer[\"data\"], cancer[\"target\"].reshape(-1, 1)])\n",
    "col_names = np.hstack([cancer[\"feature_names\"], [\"target\"]])\n",
    "cancer_df = pd.DataFrame(data, columns=col_names)\n",
    "\n",
    "X_cancer, y_cancer = cancer_df.iloc[:, :-1], cancer_df.iloc[:, -1]\n",
    "\n",
    "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(X_cancer, y_cancer, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "72545aac55787b3309d411b7ce95e07a",
     "grade": false,
     "grade_id": "cell-db02af58c38d0e3a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def answer_seven():\n",
    "    results = None\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4b8be3d6558452754f975c4b77f675c6",
     "grade": true,
     "grade_id": "cell-f2ab9c6d6d2058a7",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_seven()\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Q7: You should return a tuple (of two arrays)\"\n",
    "assert stu_ans[0].shape == (6, ), \"Q7: Please check the shape of your first returned array: it should be (6,).\"\n",
    "assert stu_ans[1].shape == (6, ), \"Q7: Please check the shape of your second returned array: it should be (6,).\"\n",
    "\n",
    "del stu_ans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9663bbc9bc95f6c139fa34dbc48f3137",
     "grade": false,
     "grade_id": "cell-1e38c3be0e8cd2a4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 8. (5 points)  \n",
    "\n",
    "Based on the scores from question 7, what gamma value corresponds to a model that is underfitting? What gamma value corresponds to a model that is overfitting? What choice of gamma would provide a model with good generalization performance on this dataset?\n",
    "\n",
    "(Hint: Try plotting the scores from question 7 to visualize the relationship. Code is provided below.)\n",
    "\n",
    "This function should return a tuple with the gamma values in this order: (Underfitting, Overfitting, Good_Generalization)\n",
    "You must enter these values in the format 1e-N, where N is the exponent, and the gamma value must be one of the values in the list `[1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]`.  Some answers have more than one value that will be accepted as correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9fa4ca1ac389c683b193ade6f15dc3d7",
     "grade": false,
     "grade_id": "cell-1dfedc819ebff323",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer_seven' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-31f24cb757e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_seven\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Remember to comment it out before submitting the notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'answer_seven' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "a,b = answer_seven()\n",
    "\n",
    "# Remember to comment it out before submitting the notebook\n",
    "# uncomment to plot\n",
    "# x = np.arange(-7, -1, 1)\n",
    "# plt.figure()\n",
    "# plt.plot(x, a)\n",
    "# plt.plot(x, b)\n",
    "# plt.xticks(x)\n",
    "# plt.xlabel('log scale: gamma parameter')\n",
    "# plt.show()\n",
    "\n",
    "def answer_eight():\n",
    "    result = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7eea689e80002365ef35e8d2101b0764",
     "grade": true,
     "grade_id": "cell-50694160622bff71",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_eight()\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Q8: You should return a tuple.\"\n",
    "assert len(stu_ans) == 3, \"Q8: Your tuple must have 3 elements.\"\n",
    "\n",
    "del stu_ans"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_supervised_learning_v1_assignment2"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
