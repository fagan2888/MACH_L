{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMEMBER\n",
    "- UNCOMMENT OUT THE GRAPHICS PORTIONS \n",
    "- DOUBLE CHECK ANSWERS \n",
    "- https://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author:  Tom Bresee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1 - SIADS 542"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### University of Michigan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "daa5a49ec1e1d1e18096d760097d2863",
     "grade": false,
     "grade_id": "cell-1262282752ee17cb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"v1.6.083120\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3e39418d18aab55b953d349a7ffb0afc",
     "grade": false,
     "grade_id": "cell-cf5099926e9f16fa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 1: Introduction to Supervised Machine Learning\n",
    "\n",
    "In this first assignment you will be using the [Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)) dataset to create a classifier that can help diagnose patients. We chose this data not only because it provides a good basis for a kNN classification problem, but also because it illustrates one of the built-in datasets that comes with `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "11ce859bbf3fe1e5ce976ec4fc3f80ad",
     "grade": false,
     "grade_id": "cell-7696bde2345190bb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# First import some necessary libararies \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17.0\n",
      "0.25.0\n",
      "0.9.0\n",
      "3.1.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specific python library versions: \n",
    "\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "print(sns.__version__)\n",
    "print(matplotlib.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- I will add in the specific scikit-learn libraries ---\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the dataset from scikit-learn. To see a description of the dataset, uncomment the print statement\n",
    "cancer = load_breast_cancer()\n",
    "# print(cancer.DESCR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <i><font color='green'>Examining the Dataset:</font></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "* _https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html_\n",
    "* _Classification dataset_\n",
    "* _Number of classes:  2_\n",
    "* _Samples per class: 212(M),357(B)_\n",
    "* _Samples total (instances): 569_\n",
    "* _Dimensionality: 30_\n",
    "* _Features: real, positive_\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(cancer.DESCR)\n",
    "\n",
    "# Data Set Characteristics:  Multivariate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DESCR\n",
      "  data\n",
      "  feature_names\n",
      "  filename\n",
      "  frame\n",
      "  target\n",
      "  target_names\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Examining the bunch object methods/possibilities\n",
    "for m in dir(cancer):\n",
    "    if not m.startswith(\"_\"):\n",
    "        print(\" \",m)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cancer.data  # raw feature data (thing big-X)\n",
    "# this is <numpy.ndarray>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cancer.feature_names # column (feature) names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Names in order:\n",
      "  0 - mean radius\n",
      "  1 - mean texture\n",
      "  2 - mean perimeter\n",
      "  3 - mean area\n",
      "  4 - mean smoothness\n",
      "  5 - mean compactness\n",
      "  6 - mean concavity\n",
      "  7 - mean concave points\n",
      "  8 - mean symmetry\n",
      "  9 - mean fractal dimension\n",
      "  10 - radius error\n",
      "  11 - texture error\n",
      "  12 - perimeter error\n",
      "  13 - area error\n",
      "  14 - smoothness error\n",
      "  15 - compactness error\n",
      "  16 - concavity error\n",
      "  17 - concave points error\n",
      "  18 - symmetry error\n",
      "  19 - fractal dimension error\n",
      "  20 - worst radius\n",
      "  21 - worst texture\n",
      "  22 - worst perimeter\n",
      "  23 - worst area\n",
      "  24 - worst smoothness\n",
      "  25 - worst compactness\n",
      "  26 - worst concavity\n",
      "  27 - worst concave points\n",
      "  28 - worst symmetry\n",
      "  29 - worst fractal dimension\n",
      "\n",
      " Note:  Col names are listed on left (in pandas form)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nFeature Names in order:\")\n",
    "\n",
    "cnt = 0\n",
    "    \n",
    "for c in cancer.feature_names:\n",
    "    # column (feature) names\n",
    "   \n",
    "    print(\" \", cnt, \"-\", c)\n",
    "    cnt = cnt + 1 \n",
    "    \n",
    "print(\"\\n Note:  Col names are listed on left (in pandas form)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/conda/lib/python3.7/site-packages/sklearn/datasets/data/breast_cancer.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cancer.filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cancer.target # the labels (targets) of the dataset (think y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cancer.target_names  # target names are either M(alignant) or B(enign), i.e. 0,1\n",
    "#  this is technically a numpy.ndarray. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['malignant', 'benign']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(cancer.target_names)  # smarter way of listing out the target_names ! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Type of object:               <class 'sklearn.utils.Bunch'>\n",
      "\n",
      "Number of samples/instances:  569\n",
      "\n",
      "Number of samples/instances:  30\n",
      "\n",
      "Core data shape (X):          (569, 30)\n",
      "\n",
      "Target names:                 ['malignant' 'benign']\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "# --- Utility Function ---\n",
    "#  defining a standard bunch object utility function \n",
    "#  input:   your bunch object\n",
    "#  output:  various information about your bunch object \n",
    "\n",
    "def examine_my_bunch(bunchO, shape=(299, 299), interpolation='nearest'):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function returns data about your bunch object.  \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n-----------------------------------------------------------\")\n",
    "    print('\\nType of object:               {}'.format(type(bunchO)))\n",
    "    print('\\nNumber of samples/instances:  {}'.format(len(bunchO.data)))  \n",
    "    print('\\nNumber of samples/instances:  {}'.format(len(bunchO.feature_names))) \n",
    "    print('\\nCore data shape (X):          {}'.format(bunchO.data.shape))\n",
    "    print('\\nTarget names:                 {}'.format(bunchO.target_names))\n",
    "    \n",
    "    # won't work: \n",
    "    # print('\\nNumber of unique classes:     {}'.format(bunchO.target.nunique()))\n",
    "\n",
    "    #print('\\nTarget Breakout Count:        {},{}'.format(np.sum(bunchO.target==0, np.sum(bunchO.target==1))))\n",
    "    \n",
    "    print(\"\\n-----------------------------------------------------------\\n\")  \n",
    "\n",
    "\n",
    "examine_my_bunch(cancer)  #  use utility function \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# np.sum(cancer.target==0)\n",
    "# np.sum(cancer.target==1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cfb14346b27d991a4c739154e05d99ff",
     "grade": false,
     "grade_id": "cell-fa8993b2db96f976",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The object returned by `load_breast_cancer()` is a scikit-learn `Bunch` object, which is similar to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# We can take a look at what essential attributes it has. Feel free to explore this object yourself. \n",
    "cancer.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7837834a64c60a4a751075f41dcea3bc",
     "grade": false,
     "grade_id": "cell-5192a5893e9a8115",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 0. Warm-up (5 pts)\n",
    "\n",
    "Understanding how many features you're dealing with and what each feature represents is an essential first step in machine learning.  So, how many features are there in this dataset? Complete the function below to return the answer as an integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b569eb8bda25f1b9fe7e972cb5503792",
     "grade": false,
     "grade_id": "cell-0562c45651419b03",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def answer_zero():\n",
    "    \n",
    "    \"\"\"\n",
    "    This function returns the number of features of the breast cancer dataset as an integer. \n",
    "    \"\"\"\n",
    "    \n",
    "    # <my code>\n",
    "    \n",
    "    # although it is a bunch and you could use this format (.), we choose to use brackets to be safe\n",
    "    #   return len(cancer.feature_names'])\n",
    "    \n",
    "    return len(cancer['feature_names'])\n",
    "\n",
    "    # cancer.data.shape  =>  (569, 30)\n",
    "    # \n",
    "    # we could have also used:   len(cancer.data.shape[1])  =>  30 \n",
    "    #\n",
    "    # its overkill, but could have done a comparison to make sure these two numbers were the same\n",
    "    # with a == match  (i.e. feature_name count and shape[1] count value\n",
    "\n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "answer_zero()  # remove this ? \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c94753e2d4714bd8a0aac53529f82a9a",
     "grade": true,
     "grade_id": "cell-919dd7f0bfcbfd9a",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden Tests Below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use :  df.info() ?\n",
    "    \n",
    "# df.isnull().sum()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Sidebar - SNS Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tom = pd.DataFrame(cancer.data, columns = cancer['feature_names'])\n",
    "tom['target'] = cancer.target \n",
    "sns.countplot(tom.target);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f16030299e8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Univariate analysis\n",
    "\n",
    "f = plt.figure(figsize=(20,4))\n",
    "f.add_subplot(1,2,1)\n",
    "sns.distplot(tom['mean radius'])\n",
    "\n",
    "f.add_subplot(1,2,2)\n",
    "sns.boxplot(tom['mean radius'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8a9f11e9a1043924800a48d69e643a9a",
     "grade": false,
     "grade_id": "cell-d17102a8aade0d25",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 1. Data Transformation (10 pts)\n",
    "\n",
    "In a lot of cases, raw data may not come in a form that's amenable to further manipulation or interpretation. Therefore, we may need to transform the raw data so that it better fits our purposes. In this assignment, we will store the data in a more human-friendly tabular format as a `pd.DataFrame`.\n",
    "\n",
    "Complete the function below to return a `pd.DataFrame` of the shape `(569, 31)` with the following columns: \n",
    "```\n",
    "['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    "'mean smoothness', 'mean compactness', 'mean concavity',\n",
    "'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    "'radius error', 'texture error', 'perimeter error', 'area error',\n",
    "'smoothness error', 'compactness error', 'concavity error',\n",
    "'concave points error', 'symmetry error', 'fractal dimension error',\n",
    "'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    "'worst smoothness', 'worst compactness', 'worst concavity',\n",
    "'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
    "'target']\n",
    "```\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "87b04df423cc0e28d15bbe5febbc8074",
     "grade": false,
     "grade_id": "cell-7da0be2f62cc82c6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def answer_one():\n",
    "    \n",
    "    cancer_df = None\n",
    "    \n",
    "    #--- my code ---\n",
    "    \n",
    "    # we are trying to create a master pandas dataframe that we can later\n",
    "    # split out into X and y, and the further split to X_test/y_test, etc.\n",
    "    # if desired, could also create this into a utility function for later \n",
    "    #   -  i.e. enter your bunch object, we output X|y for you\n",
    "        \n",
    "    cancer_df = pd.DataFrame(cancer.data, columns = cancer['feature_names'])\n",
    "    #  creating pandas dataframe with input cancer.data, and specific column names (of features)\n",
    "    \n",
    "    cancer_df['target'] = cancer.target \n",
    "    #  need to create additional column for the target values\n",
    "    \n",
    "    # print(cancer_df)\n",
    "    \n",
    "    return cancer_df\n",
    "    # return effectively a X|y matrix \n",
    "    \n",
    "    raise NotImplementedError()\n",
    "    \n",
    "# answer_one()\n",
    "    \n",
    "# CORRECT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "92ee4d53cd27146a8be39d02f63795ef",
     "grade": true,
     "grade_id": "cell-50152fa70665c294",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_one()\n",
    "\n",
    "assert stu_ans.shape == (569, 31), \"Q1: The shape of your dataframe isn't correct. \"\n",
    "\n",
    "assert list(stu_ans.columns) == ['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
    "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
    "       'smoothness error', 'compactness error', 'concavity error',\n",
    "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
    "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
    "       'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
    "       'target'], \"Q1: Please check the column names of your dataframe.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "7        13.71         20.83           90.20      577.9          0.11890   \n",
       "8        13.00         21.82           87.50      519.8          0.12730   \n",
       "9        12.46         24.04           83.97      475.9          0.11860   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760         0.30010              0.14710         0.2419   \n",
       "1           0.07864         0.08690              0.07017         0.1812   \n",
       "2           0.15990         0.19740              0.12790         0.2069   \n",
       "3           0.28390         0.24140              0.10520         0.2597   \n",
       "4           0.13280         0.19800              0.10430         0.1809   \n",
       "5           0.17000         0.15780              0.08089         0.2087   \n",
       "6           0.10900         0.11270              0.07400         0.1794   \n",
       "7           0.16450         0.09366              0.05985         0.2196   \n",
       "8           0.19320         0.18590              0.09353         0.2350   \n",
       "9           0.23960         0.22730              0.08543         0.2030   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "5                 0.07613  ...          23.75           103.40       741.6   \n",
       "6                 0.05742  ...          27.66           153.20      1606.0   \n",
       "7                 0.07451  ...          28.14           110.60       897.0   \n",
       "8                 0.07389  ...          30.73           106.20       739.3   \n",
       "9                 0.08243  ...          40.68            97.65       711.4   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "5            0.1791             0.5249           0.5355                0.1741   \n",
       "6            0.1442             0.2576           0.3784                0.1932   \n",
       "7            0.1654             0.3682           0.2678                0.1556   \n",
       "8            0.1703             0.5401           0.5390                0.2060   \n",
       "9            0.1853             1.0580           1.1050                0.2210   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "5          0.3985                  0.12440       0  \n",
       "6          0.3063                  0.08368       0  \n",
       "7          0.3196                  0.11510       0  \n",
       "8          0.4378                  0.10720       0  \n",
       "9          0.4366                  0.20750       0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# as a reference to understand the data, we show first 10 rows here...\n",
    "dft = answer_one(); display(dft.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a78261568dfb9f1adeafa68b99ef8585",
     "grade": false,
     "grade_id": "cell-151d159eb6cc7465",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 2. Class Distribution (5 pts) \n",
    "\n",
    "It's often a good idea to get some descriptive statistics, such as mean and variance of certain features, on the data at hand to understand the big picture. \n",
    "\n",
    "In particular, it's always a good idea to ask: what is the class distribution? That is, how many instances belong to the *malignant* class (encoded as 0) and the *benign* class (encoded as 1), respectively? Complete the function below to return the class distribution as a `pd.Series` of length 2 whose index is  `['malignant', 'benign']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "7        13.71         20.83           90.20      577.9          0.11890   \n",
       "8        13.00         21.82           87.50      519.8          0.12730   \n",
       "9        12.46         24.04           83.97      475.9          0.11860   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760         0.30010              0.14710         0.2419   \n",
       "1           0.07864         0.08690              0.07017         0.1812   \n",
       "2           0.15990         0.19740              0.12790         0.2069   \n",
       "3           0.28390         0.24140              0.10520         0.2597   \n",
       "4           0.13280         0.19800              0.10430         0.1809   \n",
       "5           0.17000         0.15780              0.08089         0.2087   \n",
       "6           0.10900         0.11270              0.07400         0.1794   \n",
       "7           0.16450         0.09366              0.05985         0.2196   \n",
       "8           0.19320         0.18590              0.09353         0.2350   \n",
       "9           0.23960         0.22730              0.08543         0.2030   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "5                 0.07613  ...          23.75           103.40       741.6   \n",
       "6                 0.05742  ...          27.66           153.20      1606.0   \n",
       "7                 0.07451  ...          28.14           110.60       897.0   \n",
       "8                 0.07389  ...          30.73           106.20       739.3   \n",
       "9                 0.08243  ...          40.68            97.65       711.4   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "5            0.1791             0.5249           0.5355                0.1741   \n",
       "6            0.1442             0.2576           0.3784                0.1932   \n",
       "7            0.1654             0.3682           0.2678                0.1556   \n",
       "8            0.1703             0.5401           0.5390                0.2060   \n",
       "9            0.1853             1.0580           1.1050                0.2210   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "5          0.3985                  0.12440       0  \n",
       "6          0.3063                  0.08368       0  \n",
       "7          0.3196                  0.11510       0  \n",
       "8          0.4378                  0.10720       0  \n",
       "9          0.4366                  0.20750       0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# temp\n",
    "\n",
    "dft = answer_one()\n",
    "display(dft.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cancer.target_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "50ea77f29998202242b8fc589a06d7b6",
     "grade": false,
     "grade_id": "cell-fac24fc5a519ef06",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "malignant    212\n",
       "benign       357\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def answer_two():\n",
    "\n",
    "    dist = None\n",
    "    \n",
    "    #--- my code ---\n",
    "    \n",
    "    # Note: There are many approaches that will work here\n",
    "    # I will need to create the panda series such that the index are two values (the target_name classes)\n",
    "    # Each index will be associated with a single value (the number of instances of said class)\n",
    "    #   -  np.sum(cancer.target==0), np.sum(cancer.target==1)\n",
    "    #   -  Or choose the very most streamlined way to be pythonic \n",
    "    #   -  Generally to count distinct values in single column, u use Series.value_counts\n",
    "       \n",
    "    df = answer_one()\n",
    "    # master dataframe\n",
    "    \n",
    "    dist = df.target.value_counts().sort_index() \n",
    "    # i personally like adding: .value_counts(ascending=False), but will use .sort_index()     \n",
    "        \n",
    "    #  print(dist.index)  =>   Int64Index([1, 0], dtype='int64')\n",
    "    \n",
    "    #  cancer.target_names =>  array(['malignant', 'benign'], dtype='<U9')\n",
    "    \n",
    "    \n",
    "    # we will need to change the index values to be our class NAMES \n",
    "    # and we will do it the SAFE way, direct equality \n",
    "    dist.index = list(cancer.target_names)\n",
    "    # this way it will work for any future function you use... \n",
    "    \n",
    "    return dist\n",
    "\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "answer_two() \n",
    "\n",
    "\n",
    "\n",
    "# --- df.target.value_counts() ---\n",
    "#      1    357\n",
    "#      0    212\n",
    "#      Name: target, dtype: int64 \n",
    "#  * but see how the index isn't in order ?  \n",
    "  \n",
    "    \n",
    "# --- cancer.target_names ---\n",
    "#       array(['malignant', 'benign'], dtype='<U9')\n",
    "\n",
    "\n",
    "# --- output type ---\n",
    "#   <class 'pandas.core.series.Series'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "620d2ce47498341c76fd5e39c245a34a",
     "grade": true,
     "grade_id": "cell-1ebcc2fe5b95b5df",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_two()\n",
    "\n",
    "assert isinstance(stu_ans, pd.Series), \"Q2: Your result should be a pd.Series.\"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "50408d3338c749f48f8827a5dc46afac",
     "grade": false,
     "grade_id": "cell-33882a911ba5c477",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 3. Data Preparation (5 pts)\n",
    "\n",
    "Training a classifier is a *supervised* machine learning problem, in which each instance $x_i$ has a corresponding class label $y_i$. All the instances $x_i$'s are collected into a matrix $X$ (with one instance per row of $X$), and all the corresponding labels are put into a column vector $y$. \n",
    "\n",
    "Now let's prepare the data for use with `scikit-learn`. Complete the function below to split our DataFrame into `X` (the data) and `y` (the labels), and to return them as a `tuple`, where\n",
    "* `X` is a `pd.DataFrame` of the shape `(569, 30)`\n",
    "* `y` is a `pd.Series` of the shape `(569,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f1acf373d17f75cdb2a413a8c7165da2",
     "grade": false,
     "grade_id": "cell-61b34fdd39e99b03",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       " 0          17.99         10.38          122.80     1001.0          0.11840   \n",
       " 1          20.57         17.77          132.90     1326.0          0.08474   \n",
       " 2          19.69         21.25          130.00     1203.0          0.10960   \n",
       " 3          11.42         20.38           77.58      386.1          0.14250   \n",
       " 4          20.29         14.34          135.10     1297.0          0.10030   \n",
       " ..           ...           ...             ...        ...              ...   \n",
       " 564        21.56         22.39          142.00     1479.0          0.11100   \n",
       " 565        20.13         28.25          131.20     1261.0          0.09780   \n",
       " 566        16.60         28.08          108.30      858.1          0.08455   \n",
       " 567        20.60         29.33          140.10     1265.0          0.11780   \n",
       " 568         7.76         24.54           47.92      181.0          0.05263   \n",
       " \n",
       "      mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       " 0             0.27760         0.30010              0.14710         0.2419   \n",
       " 1             0.07864         0.08690              0.07017         0.1812   \n",
       " 2             0.15990         0.19740              0.12790         0.2069   \n",
       " 3             0.28390         0.24140              0.10520         0.2597   \n",
       " 4             0.13280         0.19800              0.10430         0.1809   \n",
       " ..                ...             ...                  ...            ...   \n",
       " 564           0.11590         0.24390              0.13890         0.1726   \n",
       " 565           0.10340         0.14400              0.09791         0.1752   \n",
       " 566           0.10230         0.09251              0.05302         0.1590   \n",
       " 567           0.27700         0.35140              0.15200         0.2397   \n",
       " 568           0.04362         0.00000              0.00000         0.1587   \n",
       " \n",
       "      mean fractal dimension  ...  worst radius  worst texture  \\\n",
       " 0                   0.07871  ...        25.380          17.33   \n",
       " 1                   0.05667  ...        24.990          23.41   \n",
       " 2                   0.05999  ...        23.570          25.53   \n",
       " 3                   0.09744  ...        14.910          26.50   \n",
       " 4                   0.05883  ...        22.540          16.67   \n",
       " ..                      ...  ...           ...            ...   \n",
       " 564                 0.05623  ...        25.450          26.40   \n",
       " 565                 0.05533  ...        23.690          38.25   \n",
       " 566                 0.05648  ...        18.980          34.12   \n",
       " 567                 0.07016  ...        25.740          39.42   \n",
       " 568                 0.05884  ...         9.456          30.37   \n",
       " \n",
       "      worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       " 0             184.60      2019.0           0.16220            0.66560   \n",
       " 1             158.80      1956.0           0.12380            0.18660   \n",
       " 2             152.50      1709.0           0.14440            0.42450   \n",
       " 3              98.87       567.7           0.20980            0.86630   \n",
       " 4             152.20      1575.0           0.13740            0.20500   \n",
       " ..               ...         ...               ...                ...   \n",
       " 564           166.10      2027.0           0.14100            0.21130   \n",
       " 565           155.00      1731.0           0.11660            0.19220   \n",
       " 566           126.70      1124.0           0.11390            0.30940   \n",
       " 567           184.60      1821.0           0.16500            0.86810   \n",
       " 568            59.16       268.6           0.08996            0.06444   \n",
       " \n",
       "      worst concavity  worst concave points  worst symmetry  \\\n",
       " 0             0.7119                0.2654          0.4601   \n",
       " 1             0.2416                0.1860          0.2750   \n",
       " 2             0.4504                0.2430          0.3613   \n",
       " 3             0.6869                0.2575          0.6638   \n",
       " 4             0.4000                0.1625          0.2364   \n",
       " ..               ...                   ...             ...   \n",
       " 564           0.4107                0.2216          0.2060   \n",
       " 565           0.3215                0.1628          0.2572   \n",
       " 566           0.3403                0.1418          0.2218   \n",
       " 567           0.9387                0.2650          0.4087   \n",
       " 568           0.0000                0.0000          0.2871   \n",
       " \n",
       "      worst fractal dimension  \n",
       " 0                    0.11890  \n",
       " 1                    0.08902  \n",
       " 2                    0.08758  \n",
       " 3                    0.17300  \n",
       " 4                    0.07678  \n",
       " ..                       ...  \n",
       " 564                  0.07115  \n",
       " 565                  0.06637  \n",
       " 566                  0.07820  \n",
       " 567                  0.12400  \n",
       " 568                  0.07039  \n",
       " \n",
       " [569 rows x 30 columns], 0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       "       ..\n",
       " 564    0\n",
       " 565    0\n",
       " 566    0\n",
       " 567    0\n",
       " 568    1\n",
       " Name: target, Length: 569, dtype: int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def answer_three():\n",
    "    \n",
    "    X, y = None, None\n",
    "\n",
    "    # --- my code ----\n",
    "    \n",
    "    df = answer_one()\n",
    "    # master dataframe\n",
    "    # display(df)\n",
    "    \n",
    "    # print(df.shape)  =>  (569, 31)\n",
    "    \n",
    "    X = df.drop(columns='target')\n",
    "    # (569, 30)\n",
    "    \n",
    "    y = df.target  \n",
    "    # or df['target']\n",
    "    # technically this is a series, its a single col from the original df \n",
    "    # (569,)\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "answer_three()\n",
    "\n",
    "# do we care if there column headers are labelled in the df ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4fe0be78d55346f1a7e5ce60c2e7cd86",
     "grade": true,
     "grade_id": "cell-0bd5392f7412ea87",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_three()\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Q3: You should return a tuple!\"\n",
    "assert stu_ans[0].shape == (569, 30), \"Q3: Please check the shape of X.\"\n",
    "assert stu_ans[1].shape == (569,), \"Q3: Please check the shape of y.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "059c086ea299afaea520c438cb634767",
     "grade": false,
     "grade_id": "cell-69dd1eef26cd5aac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 4. Train-test Split (10 pts)\n",
    "\n",
    "For a typical machine learning problem, we'd need two separate datasets, one for training a model and the other for evaluating the trained model for its generalisability to unseen data. `scikit-learn` provides a very handy [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function for this purpose.  \n",
    "\n",
    "Now, complete the function below that uses the `train_test_split` function to split `X` and `y` into training and testing sets. Your function should return a `tuple` `(X_train, X_test, y_train, and y_test)` where\n",
    "\n",
    "\n",
    "* `X_train` is of the shape `(426, 30)`\n",
    "* `X_test` is of the shape `(143, 30)`\n",
    "* `y_train` is of the shape `(426,)`\n",
    "* `y_test` is of the shape `(143,)`\n",
    "\n",
    "**IMPORTANT: Set the random number generator state to the number 42 by specifying `random_state=42` to ensure a deterministic result that matches that of the autograder.**   Why the number 42?  Please see: https://www.theguardian.com/books/2011/feb/03/douglas-adams-42-hitchhiker\n",
    "\n",
    "(In later work, we'll actually use a slightly more sophisticated splitting scheme that uses training, validation, and test sets, but we'll cover this later as part of a technique called cross-validation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "07047400cd0a7093d7a1ea683fc3b4a7",
     "grade": false,
     "grade_id": "cell-8e5c85428bc3e008",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       " 287       12.890         13.12           81.89      515.9          0.06955   \n",
       " 512       13.400         20.52           88.64      556.7          0.11060   \n",
       " 402       12.960         18.29           84.18      525.2          0.07351   \n",
       " 446       17.750         28.03          117.30      981.6          0.09997   \n",
       " 210       20.580         22.14          134.70     1290.0          0.09090   \n",
       " ..           ...           ...             ...        ...              ...   \n",
       " 71         8.888         14.64           58.79      244.0          0.09783   \n",
       " 106       11.640         18.33           75.17      412.5          0.11420   \n",
       " 270       14.290         16.82           90.30      632.6          0.06429   \n",
       " 435       13.980         19.62           91.12      599.5          0.10600   \n",
       " 102       12.180         20.52           77.22      458.7          0.08013   \n",
       " \n",
       "      mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       " 287           0.03729         0.02260              0.01171         0.1337   \n",
       " 512           0.14690         0.14450              0.08172         0.2116   \n",
       " 402           0.07899         0.04057              0.01883         0.1874   \n",
       " 446           0.13140         0.16980              0.08293         0.1713   \n",
       " 210           0.13480         0.16400              0.09561         0.1765   \n",
       " ..                ...             ...                  ...            ...   \n",
       " 71            0.15310         0.08606              0.02872         0.1902   \n",
       " 106           0.10170         0.07070              0.03485         0.1801   \n",
       " 270           0.02675         0.00725              0.00625         0.1508   \n",
       " 435           0.11330         0.11260              0.06463         0.1669   \n",
       " 102           0.04038         0.02383              0.01770         0.1739   \n",
       " \n",
       "      mean fractal dimension  ...  worst radius  worst texture  \\\n",
       " 287                 0.05581  ...        13.620          15.54   \n",
       " 512                 0.07325  ...        16.410          29.66   \n",
       " 402                 0.05899  ...        14.130          24.61   \n",
       " 446                 0.05916  ...        21.530          38.54   \n",
       " 210                 0.05024  ...        23.240          27.84   \n",
       " ..                      ...  ...           ...            ...   \n",
       " 71                  0.08980  ...         9.733          15.67   \n",
       " 106                 0.06520  ...        13.140          29.26   \n",
       " 270                 0.05376  ...        14.910          20.65   \n",
       " 435                 0.06544  ...        17.040          30.80   \n",
       " 102                 0.05677  ...        13.340          32.84   \n",
       " \n",
       "      worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       " 287            87.40       577.0           0.09616            0.11470   \n",
       " 512           113.30       844.4           0.15740            0.38560   \n",
       " 402            96.31       621.9           0.09329            0.23180   \n",
       " 446           145.40      1437.0           0.14010            0.37620   \n",
       " 210           158.30      1656.0           0.11780            0.29200   \n",
       " ..               ...         ...               ...                ...   \n",
       " 71             62.56       284.4           0.12070            0.24360   \n",
       " 106            85.51       521.7           0.16880            0.26600   \n",
       " 270            94.44       684.6           0.08567            0.05036   \n",
       " 435           113.90       869.3           0.16130            0.35680   \n",
       " 102            84.58       547.8           0.11230            0.08862   \n",
       " \n",
       "      worst concavity  worst concave points  worst symmetry  \\\n",
       " 287          0.11860               0.05366          0.2309   \n",
       " 512          0.51060               0.20510          0.3585   \n",
       " 402          0.16040               0.06608          0.3207   \n",
       " 446          0.63990               0.19700          0.2972   \n",
       " 210          0.38610               0.19200          0.2909   \n",
       " ..               ...                   ...             ...   \n",
       " 71           0.14340               0.04786          0.2254   \n",
       " 106          0.28730               0.12180          0.2806   \n",
       " 270          0.03866               0.03333          0.2458   \n",
       " 435          0.40690               0.18270          0.3179   \n",
       " 102          0.11450               0.07431          0.2694   \n",
       " \n",
       "      worst fractal dimension  \n",
       " 287                  0.06915  \n",
       " 512                  0.11090  \n",
       " 402                  0.07247  \n",
       " 446                  0.09075  \n",
       " 210                  0.05865  \n",
       " ..                       ...  \n",
       " 71                   0.10840  \n",
       " 106                  0.09097  \n",
       " 270                  0.06120  \n",
       " 435                  0.10550  \n",
       " 102                  0.06878  \n",
       " \n",
       " [426 rows x 30 columns],\n",
       "      mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       " 204        12.47         18.60           81.09      481.9          0.09965   \n",
       " 70         18.94         21.31          123.60     1130.0          0.09009   \n",
       " 131        15.46         19.48          101.70      748.9          0.10920   \n",
       " 431        12.40         17.68           81.47      467.8          0.10540   \n",
       " 540        11.54         14.44           74.65      402.9          0.09984   \n",
       " ..           ...           ...             ...        ...              ...   \n",
       " 89         14.64         15.24           95.77      651.9          0.11320   \n",
       " 199        14.45         20.22           94.49      642.7          0.09872   \n",
       " 411        11.04         16.83           70.92      373.2          0.10770   \n",
       " 18         19.81         22.15          130.00     1260.0          0.09831   \n",
       " 390        10.26         12.22           65.75      321.6          0.09996   \n",
       " \n",
       "      mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       " 204           0.10580         0.08005              0.03821         0.1925   \n",
       " 70            0.10290         0.10800              0.07951         0.1582   \n",
       " 131           0.12230         0.14660              0.08087         0.1931   \n",
       " 431           0.13160         0.07741              0.02799         0.1811   \n",
       " 540           0.11200         0.06737              0.02594         0.1818   \n",
       " ..                ...             ...                  ...            ...   \n",
       " 89            0.13390         0.09966              0.07064         0.2116   \n",
       " 199           0.12060         0.11800              0.05980         0.1950   \n",
       " 411           0.07804         0.03046              0.02480         0.1714   \n",
       " 18            0.10270         0.14790              0.09498         0.1582   \n",
       " 390           0.07542         0.01923              0.01968         0.1800   \n",
       " \n",
       "      mean fractal dimension  ...  worst radius  worst texture  \\\n",
       " 204                 0.06373  ...         14.97          24.64   \n",
       " 70                  0.05461  ...         24.86          26.58   \n",
       " 131                 0.05796  ...         19.26          26.00   \n",
       " 431                 0.07102  ...         12.88          22.91   \n",
       " 540                 0.06782  ...         12.26          19.68   \n",
       " ..                      ...  ...           ...            ...   \n",
       " 89                  0.06346  ...         16.34          18.24   \n",
       " 199                 0.06466  ...         18.33          30.12   \n",
       " 411                 0.06340  ...         12.41          26.44   \n",
       " 18                  0.05395  ...         27.32          30.88   \n",
       " 390                 0.06569  ...         11.38          15.65   \n",
       " \n",
       "      worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       " 204            96.05       677.9            0.1426             0.2378   \n",
       " 70            165.90      1866.0            0.1193             0.2336   \n",
       " 131           124.90      1156.0            0.1546             0.2394   \n",
       " 431            89.61       515.8            0.1450             0.2629   \n",
       " 540            78.78       457.8            0.1345             0.2118   \n",
       " ..               ...         ...               ...                ...   \n",
       " 89            109.40       803.6            0.1277             0.3089   \n",
       " 199           117.90      1044.0            0.1552             0.4056   \n",
       " 411            79.93       471.4            0.1369             0.1482   \n",
       " 18            186.80      2398.0            0.1512             0.3150   \n",
       " 390            73.23       394.5            0.1343             0.1650   \n",
       " \n",
       "      worst concavity  worst concave points  worst symmetry  \\\n",
       " 204          0.26710               0.10150          0.3014   \n",
       " 70           0.26870               0.17890          0.2551   \n",
       " 131          0.37910               0.15140          0.2837   \n",
       " 431          0.24030               0.07370          0.2556   \n",
       " 540          0.17970               0.06918          0.2329   \n",
       " ..               ...                   ...             ...   \n",
       " 89           0.26040               0.13970          0.3151   \n",
       " 199          0.49670               0.18380          0.4753   \n",
       " 411          0.10670               0.07431          0.2998   \n",
       " 18           0.53720               0.23880          0.2768   \n",
       " 390          0.08615               0.06696          0.2937   \n",
       " \n",
       "      worst fractal dimension  \n",
       " 204                  0.08750  \n",
       " 70                   0.06589  \n",
       " 131                  0.08019  \n",
       " 431                  0.09359  \n",
       " 540                  0.08134  \n",
       " ..                       ...  \n",
       " 89                   0.08473  \n",
       " 199                  0.10130  \n",
       " 411                  0.07881  \n",
       " 18                   0.07615  \n",
       " 390                  0.07722  \n",
       " \n",
       " [143 rows x 30 columns],\n",
       " 287    1\n",
       " 512    0\n",
       " 402    1\n",
       " 446    0\n",
       " 210    0\n",
       "       ..\n",
       " 71     1\n",
       " 106    1\n",
       " 270    1\n",
       " 435    0\n",
       " 102    1\n",
       " Name: target, Length: 426, dtype: int64,\n",
       " 204    1\n",
       " 70     0\n",
       " 131    0\n",
       " 431    1\n",
       " 540    1\n",
       "       ..\n",
       " 89     1\n",
       " 199    0\n",
       " 411    1\n",
       " 18     0\n",
       " 390    1\n",
       " Name: target, Length: 143, dtype: int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# our core sklearn splitting function \n",
    "\n",
    "\n",
    "def answer_four():\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = (None, ) * 4\n",
    "    \n",
    "    # --- my code ---\n",
    "    \n",
    "    X, y = answer_three()\n",
    "    # We will use answer three which broke out our core X and y matrices as starting point\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    #  Break the X and y to their train/test ratios, default should be .75/.25\n",
    "    #  READ:  you better make sure you use random_state=42 for rest of assignment ! \n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    # i always find it interesting that you dont actually have to put () around the tuple output \n",
    "    \n",
    "\n",
    "answer_four()\n",
    "\n",
    "#  This will return four physical matrices. \n",
    "#  If you want the first, just say answer_four()[0], etc. \n",
    "#  Math: \n",
    "#    - Default sklearn should be 75%/25% ratio \n",
    "#    - \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quick math check:\n",
      "You should have a calculated ratio of .75 !\n",
      "Your calculated ratio is:  0.75 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mathcheck = answer_four()\n",
    "\n",
    "print(\"\\nQuick math check:\")\n",
    "print(\"You should have a calculated ratio of .75 !\")\n",
    "\n",
    "print(\"Your calculated ratio is: \", round(mathcheck[0].shape[0] / 569, 2), \"\\n\")\n",
    "# Is the X_test 75% of the total (569 entries) ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "49a1560f285f57d78e10ec222e74a411",
     "grade": true,
     "grade_id": "cell-7c3f4473c01b46df",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_four()\n",
    "\n",
    "assert stu_ans[0].shape == (426, 30), \"Q4: Please check the shape of X_train.\"\n",
    "assert stu_ans[1].shape == (143, 30), \"Q4: Please check the shape of X_test.\"\n",
    "assert stu_ans[2].shape == (426,), \"Q4: Please check the shape of y_train.\"\n",
    "assert stu_ans[3].shape == (143,), \"Q4: Please check the shape of y_test.\"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4ac8dec823c48ef7fc516164b6531c99",
     "grade": false,
     "grade_id": "cell-eef73d2512084cc8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 5. kNN Classifier Construction (5 pts)\n",
    "\n",
    "Use `KNeighborsClassifier` from `scikit-learn` to fit a $k$-Nearest Neighbours ($k$NN) classifier with `X_train` and `y_train` where $k = 1$. Your function should return the trained classifier itself, which is a `sklearn.neighbors.KNeighborsClassifier` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <i><font color='green'>Quick sidebar:</font></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# KNN library \n",
    "\n",
    "X_train, X_test, y_train, y_test = answer_four()\n",
    "\n",
    "temp_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "temp_knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# if you were smart, you would creat a utility function here...\n",
    "#\n",
    "\n",
    "# ----------------------------\n",
    "# Methods available:\n",
    "#\n",
    "# for m in dir(temp_knn):\n",
    "#     if not m.startswith(\"_\"):\n",
    "#         print(m)\n",
    "# \n",
    "#   algorithm\n",
    "#   classes_\n",
    "#   effective_metric_\n",
    "#   effective_metric_params_\n",
    "#   fit\n",
    "#   get_params\n",
    "#   kneighbors\n",
    "#   kneighbors_graph\n",
    "#   leaf_size\n",
    "#   metric\n",
    "#   metric_params\n",
    "#   n_features_in_\n",
    "#   n_jobs\n",
    "#   n_neighbors\n",
    "#   n_samples_fit_\n",
    "#   outputs_2d_\n",
    "#   p\n",
    "#   predict\n",
    "#   predict_proba\n",
    "#   radius\n",
    "#   score\n",
    "#   set_params\n",
    "#   weights\n",
    "# ----------------------------\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "#type(temp_knn)  =>  sklearn.neighbors._classification.KNeighborsClassifier\n",
    "\n",
    "# neighbor count defaults to: 5 (if you don't specify) \n",
    "\n",
    "# https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
    "\n",
    "# temp_knn.weights   =>   'uniform'  (i.e. All points in each neighborhood are weighted equally.)\n",
    "# or i could have used 'distance' for inverse\n",
    "#  \n",
    "\n",
    "# temp_knn.algorithm  =>  'auto'\n",
    "\n",
    "# temp_knn.metric  =>  'minkowski'\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "\n",
    "\n",
    "# --- temp_knn.get_params() -\n",
    "\n",
    "# {'algorithm': 'auto',\n",
    "#  'leaf_size': 30,\n",
    "#  'metric': 'minkowski',\n",
    "#  'metric_params': None,\n",
    "#  'n_jobs': None,\n",
    "#  'n_neighbors': 5,\n",
    "#  'p': 2,\n",
    "#  'weights': 'uniform'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- underscore 'created' values ---\n",
    "#\n",
    "#  temp_knn.classes_  =>  array([0, 1])   i.e. two values... binary classifer problem... \n",
    "#  \n",
    "#  temp_knn.n_features_in_  =>  30\n",
    "#\n",
    "#  temp_knn.outputs_2d_  =>  False\n",
    "# \n",
    "#  add more...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```  \n",
    "\n",
    "# configuration parameters \n",
    "\n",
    "\n",
    "n_neighborsint, default=5\n",
    "  Number of neighbors to use by default for kneighbors queries.\n",
    "\n",
    "weights{‘uniform’, ‘distance’} or callable, default=’uniform’\n",
    "  weight function used in prediction. Possible values:\n",
    "\n",
    " ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "\n",
    " ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "\n",
    " [callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n",
    "\n",
    "    \n",
    "algorithm{‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, default=’auto’\n",
    "Algorithm used to compute the nearest neighbors:\n",
    "\n",
    "‘ball_tree’ will use BallTree\n",
    "\n",
    "‘kd_tree’ will use KDTree\n",
    "\n",
    "‘brute’ will use a brute-force search.\n",
    "\n",
    "‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.\n",
    "\n",
    "Note: fitting on sparse input will override the setting of this parameter, using brute force.\n",
    "\n",
    "    \n",
    "    \n",
    "leaf_sizeint, default=30\n",
    "  Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.\n",
    "\n",
    "\n",
    "\n",
    "pint, default=2\n",
    "  Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "\n",
    "    \n",
    "metricstr or callable, default=’minkowski’\n",
    "  the distance metric to use for the tree. The default metric is minkowski, and with p=2 is equivalent to the standard Euclidean metric. See the documentation of DistanceMetric for a list of available metrics. If metric is “precomputed”, X is assumed to be a distance matrix and must be square during fit. X may be a sparse graph, in which case only “nonzero” elements may be considered neighbors.\n",
    "\n",
    "    \n",
    "metric_paramsdict, default=None\n",
    "  Additional keyword arguments for the metric function.\n",
    "\n",
    "n_jobsint, default=None\n",
    "  The number of parallel jobs to run for neighbors search. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details. Doesn’t affect fit method.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  To calculate distances, 3 distance metrics that are often used are Euclidean Distance,\n",
    "#  Manhattan Distance, and Minkowski Distance.\n",
    "\n",
    "#  When you use Scikit-Learn, the default distance used is Euclidean. It can be seen in the \n",
    "# Minkowski distance formula that there is a Hyperparameter p, if set p = 1 then it will use\n",
    "# the Manhattan distance and p = 2 to be Euclidean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- end sidebar ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8dba13630c35dddfdcc1424b9a74e8c1",
     "grade": false,
     "grade_id": "cell-4b71f9b9bd2e9139",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# KNN library \n",
    "\n",
    "def answer_five():\n",
    "    \n",
    "    knn = None\n",
    "    \n",
    "    # --- my code ---\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    # my split out data matrices of X and y \n",
    "    # 42 was the base fyi random state... so keep using answer_four() as input ! \n",
    "       \n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    # \n",
    "    # initiate (create) a KNN neighbors classifier object, assuming number of neighbors == 1 \n",
    "    # \n",
    "    # type(knn)  = >  <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
    "    \n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    # Fit the model using X_train as training data and y_train as target values\n",
    "    # FYI, i could have chained both steps at the same time \n",
    "    \n",
    "    return knn\n",
    "\n",
    "answer_five()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6e9a173daec649e6c9352961cf3909e7",
     "grade": true,
     "grade_id": "cell-746df875c076339d",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_five()\n",
    "assert isinstance(stu_ans, KNeighborsClassifier), \"Q5: Please build the required kNN classifier.\"\n",
    "assert len(stu_ans.classes_) == 2, \"Q5: Your kNN classifier was trained with an incorrect # classes. \"\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2f626c2c26008ad59fa441c7d2db3fc7",
     "grade": false,
     "grade_id": "cell-2ae5512e5f925fd8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 6. kNN Prediction on Mean Vector (10 pts)\n",
    "\n",
    "It's often useful and interesting to know what class a \"typical\" or \"average\" data point belongs to. Use your kNN classifier from the last question to predict the class label for the *mean vector* of the training data. Your function should return the predicted class label as a singleton numpy array --- either `array([ 0.])` or `array([ 1.])`. \n",
    "\n",
    "If you encounter errors complaining that the shape of your data isn't correct, carefully check the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.predict) of the `predict` function. Another useful hint is to consider what kind of object `X_train` is. How do you make sure it is in the correct shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e84ea41c713038387cb2dd472988182f",
     "grade": false,
     "grade_id": "cell-bbc431b30a17745f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def answer_six():\n",
    "    \n",
    "    pred = None\n",
    "\n",
    "    # --- my code here ---\n",
    "    \n",
    "    df = answer_one()\n",
    "    \n",
    "    means = df.mean()[:-1].values.reshape(1, -1)\n",
    "    #  Key:  the .reshape(1,-1) command does the following:\n",
    "    #  \n",
    "    #    print(type(means))      ==   <class 'numpy.ndarray'>\n",
    "    \n",
    "    knn = answer_five()\n",
    "    \n",
    "    pred = knn.predict(means)\n",
    "    \n",
    "    return pred\n",
    "\n",
    "answer_six()\n",
    "\n",
    "\n",
    "# could be wrong, may either need to e array[1.]  OR  array[0.]\n",
    "# Assume:  array([1]) is correct (how prove ?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "494638ad6ea8a1ed997da2a1028c34d1",
     "grade": true,
     "grade_id": "cell-c93e4911f581b5cb",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_six()\n",
    "\n",
    "assert isinstance(stu_ans, np.ndarray), \"Q6: Your function should return a np.ndarray. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "acebbf177184da50e3d30ea12c5b5f97",
     "grade": false,
     "grade_id": "cell-cba29490ecc74222",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 7. kNN Prediction on the Test Set (5 pts)\n",
    "\n",
    "Now, use your kNN classifier to predict class labels for the test set `X_test`. Your function should return a binary `np.ndarray` of the shape `(143,)` whose values are either `0.0` or `1.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ac1828dd71189cd5cbfa7f7fa4713b9a",
     "grade": false,
     "grade_id": "cell-556e3b89a523853a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def answer_seven():\n",
    "    \n",
    "    preds = None\n",
    "    \n",
    "    # --- my code ---\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    # note that X_test is 25% of the total, i.e. 143 entries\n",
    "    \n",
    "    knn = answer_five()\n",
    "    \n",
    "    preds = knn.predict(X_test)\n",
    "    # I am \n",
    "    \n",
    "    #     print(y_test)\n",
    "    #     print(knn.predict(X_test).shape)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "\n",
    "# --- temp ---\n",
    "\n",
    "#  temp = answer_seven()\n",
    "\n",
    "#  temp.shape  =>   (143,) \n",
    "\n",
    "#  type(temp)  =>   numpy.ndarray\n",
    "\n",
    "#  print(temp)\n",
    "\n",
    "#  array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
    "#         0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
    "#         1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
    "#         0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
    "#         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
    "#         0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
    "#         0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1])\n",
    "\n",
    "#   len(temp)  =>  143 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1eb28af45e0c38e4506e3b11fa04622f",
     "grade": true,
     "grade_id": "cell-1fc7ffa2d7e05814",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_seven()\n",
    "assert isinstance(stu_ans, np.ndarray), \"Q7: Your function should return a np.ndarray. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "01c3548a6770290943242e4572fa04fa",
     "grade": false,
     "grade_id": "cell-9b690a899cf1faea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 8. Evaluation on the Test Set (5 pts) \n",
    "\n",
    "Once you have the predictions on the test set, you may compare them with the ground-truth labels to gauge how well your model performs when given unseen data. \n",
    "\n",
    "Complete the function below to compute the score (mean accuracy) of your kNN classifier using the test set `X_test` and the test labels `y_test`. The function should return a `float` between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "116e205832d7734f41a6c6d07a90d1c7",
     "grade": false,
     "grade_id": "cell-dc56668e96e99a63",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9300699300699301"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def answer_eight():\n",
    "    \n",
    "    score = None\n",
    "    \n",
    "    # ---  my code here ---\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    \n",
    "    knn = answer_five()\n",
    "   \n",
    "    score = knn.score(X_test, y_test)\n",
    "    # i input the X_test and y_test, and it compares what it predicted vs reality, and then\n",
    "    # outputs a raw ratio score, very simple...\n",
    "    # I could round it if i wanted... \n",
    "      \n",
    "    return score\n",
    "\n",
    "answer_eight()\n",
    "\n",
    "\n",
    "# final answer:  0.9300699300699301 (not bad) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "43e6c71469a655accc05570c3f17ac5a",
     "grade": true,
     "grade_id": "cell-edfa0ff11db4a6d9",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_eight()\n",
    "\n",
    "assert isinstance(stu_ans, float), \"Q8: Your function should return a float. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "78c6a2f4fee484176f75455a6c91cab7",
     "grade": false,
     "grade_id": "cell-2f4bb718715b7db8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Optional plot\n",
    "\n",
    "Note: The following plots will help you to evaluate the model with showing the prediction accuracy in training and testing set.\n",
    "\n",
    "Try using the plotting function below to visualize the different predicition scores between training and test sets, as well as malignant and benign cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2052bee013604481351deb7fc392c409",
     "grade": false,
     "grade_id": "cell-3a29268b05bec923",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_plot(knn):\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     %matplotlib notebook\n",
    "\n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "\n",
    "    # Find the training and testing accuracies by target value (i.e. malignant, benign)\n",
    "    mal_train_X = X_train[y_train==0]\n",
    "    mal_train_y = y_train[y_train==0]\n",
    "    ben_train_X = X_train[y_train==1]\n",
    "    ben_train_y = y_train[y_train==1]\n",
    "\n",
    "    mal_test_X = X_test[y_test==0]\n",
    "    mal_test_y = y_test[y_test==0]\n",
    "    ben_test_X = X_test[y_test==1]\n",
    "    ben_test_y = y_test[y_test==1]\n",
    "\n",
    "    scores = [knn.score(mal_train_X, mal_train_y), knn.score(ben_train_X, ben_train_y), \n",
    "              knn.score(mal_test_X, mal_test_y), knn.score(ben_test_X, ben_test_y)]\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot the scores as a bar chart\n",
    "    bars = plt.bar(np.arange(4), scores, color=['#4c72b0','#4c72b0','#55a868','#55a868'])\n",
    "\n",
    "    # directly label the score onto the bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.gca().text(bar.get_x() + bar.get_width()/2, height*.90, '{0:.{1}f}'.format(height, 2), \n",
    "                     ha='center', color='w', fontsize=11)\n",
    "\n",
    "    # remove all the ticks (both axes), and tick labels on the Y axis\n",
    "    plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "    # remove the frame of the chart\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    plt.xticks([0,1,2,3], ['Malignant\\nTraining', 'Benign\\nTraining', 'Malignant\\nTest', 'Benign\\nTest'], alpha=0.8);\n",
    "    plt.title('Training and Test Accuracies for Malignant and Benign Cells', alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b86e43682bde0d595e9f71b770205319",
     "grade": false,
     "grade_id": "cell-200de5f487ac9fa1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Uncomment the below line to see the visualization. You can pass in any trained classifier as an argument.\n",
    "\n",
    "**Comment out** the the below line when submitting your notebook for grading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Remember to comment it out when submitting the notebook\n",
    "accuracy_plot(answer_five())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "807700a4417faf916e02ea785683f07f",
     "grade": false,
     "grade_id": "cell-7d573c035102d74b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 9. Hyper-parameter Tuning (5 pts)\n",
    "\n",
    "It's common to experiment with different configurations of a model, also known as \"hyper-parameters\" which are typically specified in advance of starting the step of estimating the learnable \"parameters\" of a specific model configuration in order to achieve better performance. The main crucial hyper-parameter of a k-NN model is the number $k$, the number of neighbors to examine. \n",
    "\n",
    "Change $k$ to 15 and fit the model with training data. Complete the function below to return the trained model, which is a `sklearn.neighbors.KNeighborsClassifier` object. Compare this with the results above for $k$ = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bd368f7ef582de2c6a34cd4696d5ecf3",
     "grade": false,
     "grade_id": "cell-3bc80326a3e99e05",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=15)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# KNN library\n",
    "\n",
    "\n",
    "def answer_nine():\n",
    "    \n",
    "    knn = None\n",
    "    \n",
    "    # --- my code here ---\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=15)\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    return knn\n",
    "\n",
    "answer_nine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# how am i supposed to 'compare' the two instances ?  add something technical here ! \n",
    "\n",
    "#  -  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e76b8ab979b61e4bfbb7268debe021b8",
     "grade": true,
     "grade_id": "cell-e724a46e381ed1b7",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_nine()\n",
    "assert isinstance(stu_ans, KNeighborsClassifier), \"Q9: Please build the required kNN classifier.\"\n",
    "assert len(stu_ans.classes_) == 2, \"Q9: Your kNN classifier was trained with an incorrect # classes. \"\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remember to comment it out when submitting the notebook\n",
    "accuracy_plot(answer_nine())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0905268f819993696d61ad9f9e1738d2",
     "grade": false,
     "grade_id": "cell-67fb7570879a6ed9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 10. Weighted k-NN (5 pts)\n",
    "\n",
    "Keeping $k = 15$, now change the k-NN method to use a *weighted* distance measure: this means closer neighbors of a query point will have more influence on the prediction than neighbors which are a greater distance away. (Normally, the default k-NN classifier uses a uniform weighting, i.e. it ignores how far a neighbor is and just sees that it exists.)\n",
    "\n",
    "Your function below should return a trained kNN classifier of the type `sklearn.neighbors.KNeighborsClassifier`. (You may find it helpful to plot and compare the results with the unweighted distance measure, using the provided plotting function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3ae6049618c4a782be507ccd01ee8813",
     "grade": false,
     "grade_id": "cell-4243c4d7cfa2960e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=15, weights='distance')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# KNN library\n",
    "\n",
    "def answer_ten():\n",
    "    \n",
    "    knn = None\n",
    "    \n",
    "    # --- my code here ---\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=15, weights = 'distance' )\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    return knn\n",
    "\n",
    "answer_ten()\n",
    "\n",
    "\n",
    "# https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn\n",
    "# from sklearn import metrics\n",
    "# print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# when you do differently than the defaults, you will see each manner that was changed in output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "95fb2f9eee2699563a0abaad5db8dee2",
     "grade": true,
     "grade_id": "cell-558b71c1a69189f5",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_ten()\n",
    "assert isinstance(stu_ans, KNeighborsClassifier), \"Q9: Please build the required kNN classifier.\"\n",
    "assert len(stu_ans.classes_) == 2, \"Q9: Your kNN classifier was trained with an incorrect # classes. \"\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remember to comment it out when submitting the notebook\n",
    "accuracy_plot(answer_ten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "40c306fde694591056a5b00cb143a058",
     "grade": false,
     "grade_id": "cell-991ef995f3f147aa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Question 11: Model parameter tuning (15 points)\n",
    "\n",
    "It is important to improve algorithm design through automatically changing the parameter based on data-driven evidence, because it is more effective than just 'trying out' different parameters by hand.\n",
    "\n",
    "Perform a simple parameter sweep for all **odd** values of $k$ from 1 to 19 inclusive, and return the optimal value of $k$ that leads to the highest overall *test set accuracy* on this train/test split.  Accuracy is computed using the **score** method. Your code should return an integer between 1 and 19. In case of a tie, return the smallest best $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "96d2c36c4d1078ea90306d3af7448c85",
     "grade": false,
     "grade_id": "cell-feeb5e4810d6c9e6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# there are two key ways to actually do this...\n",
    "#   1.  dictionary and then at the end grab the highest score\n",
    "#   2.  real time threshold keeper\n",
    "\n",
    "k_to_score_mapper = {}\n",
    "\n",
    "def answer_eleven():\n",
    "\n",
    "    k_best = None\n",
    "\n",
    "    # --- my code here ---\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    \n",
    "    k_sweep = [num for num in range(20) if num % 2 == 1] \n",
    "    #  this will be:  [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "\n",
    "    for kval in k_sweep:\n",
    "        \n",
    "        knnclf = KNeighborsClassifier(n_neighbors=kval)\n",
    "        # we create an instance of Neighbours Classifier and fit the data\n",
    "        \n",
    "        knnclf.fit(X_train, y_train)\n",
    "        \n",
    "        test_score = knnclf.score(X_test, y_test)\n",
    "        \n",
    "        train_score = knnclf.score(X_train, y_train)\n",
    "        \n",
    "        k_to_score_mapper[kval] = test_score\n",
    "        \n",
    "\n",
    "        \n",
    "        #print(\"K-value:\", kval, \"\\t\", \"Test Score:\", train_score)\n",
    "        \n",
    "        #\n",
    "        # --- OUTPUT OF TRAINING SET --- \n",
    "        # \n",
    "        # output of print statement: \n",
    "        # K-value: 1 \t Training Score: 1.0\n",
    "        # K-value: 3 \t Training Score: 0.9507042253521126\n",
    "        # K-value: 5 \t Training Score: 0.9342723004694836\n",
    "        # K-value: 7 \t Training Score: 0.9366197183098591\n",
    "        # K-value: 9 \t Training Score: 0.9342723004694836\n",
    "        # K-value: 11 \t Training Score: 0.9342723004694836\n",
    "        # K-value: 13 \t Training Score: 0.9248826291079812\n",
    "        # K-value: 15 \t Training Score: 0.9225352112676056\n",
    "        # K-value: 17 \t Training Score: 0.9248826291079812\n",
    "        # K-value: 19 \t Training Score: 0.92018779342723\n",
    "        #\n",
    "        #\n",
    "        # \n",
    "        # print(\"K-value:\", kval, \"\\t\", \"Test Score:\", test_score)\n",
    "        # --- OUTPUT OF THE TEST SET --- \n",
    "        #\n",
    "        # K-value: 1 \t Test Score: 0.9300699300699301\n",
    "        # K-value: 3 \t Test Score: 0.9300699300699301\n",
    "        # K-value: 5 \t Test Score: 0.965034965034965\n",
    "        # K-value: 7 \t Test Score: 0.958041958041958\n",
    "        # K-value: 9 \t Test Score: 0.958041958041958\n",
    "        # K-value: 11 \t Test Score: 0.9790209790209791 *\n",
    "        # K-value: 13 \t Test Score: 0.972027972027972\n",
    "        # K-value: 15 \t Test Score: 0.965034965034965\n",
    "        # K-value: 17 \t Test Score: 0.965034965034965\n",
    "        # K-value: 19 \t Test Score: 0.965034965034965\n",
    "        # \n",
    "                \n",
    "        \n",
    "    # print(k_to_score_mapper)\n",
    "    # dict: \n",
    "    #  {1: 0.9300699300699301, 3: 0.9300699300699301, 5: 0.965034965034965, 7: 0.958041958041958,\n",
    "    #   9: 0.958041958041958, 11: 0.9790209790209791, 13: 0.972027972027972, \n",
    "    #  15: 0.965034965034965, 17: 0.965034965034965, 19: 0.965034965034965}\n",
    "          \n",
    "    k_best = max(k_to_score_mapper, key=lambda kval: k_to_score_mapper[kval])\n",
    "    \n",
    "    return k_best\n",
    "    \n",
    "answer_eleven()\n",
    "\n",
    "\n",
    "# Comparing: \n",
    "#\n",
    "# use these in the loop:\n",
    "#    print(\"K-value:\", kval, \"\\t\", \"Test Score:\", test_score)\n",
    "#    print(\"K-value:\", kval, \"\\t\", \"Train Score:\", train_score)\n",
    "#\n",
    "# --- output --- \n",
    "#\n",
    "# K-value: 1 \t Test Score: 0.9300699300699301\n",
    "# K-value: 1 \t Train Score: 1.0\n",
    "# K-value: 3 \t Test Score: 0.9300699300699301\n",
    "# K-value: 3 \t Train Score: 0.9507042253521126\n",
    "# K-value: 5 \t Test Score: 0.965034965034965\n",
    "# K-value: 5 \t Train Score: 0.9342723004694836\n",
    "# K-value: 7 \t Test Score: 0.958041958041958\n",
    "# K-value: 7 \t Train Score: 0.9366197183098591\n",
    "# K-value: 9 \t Test Score: 0.958041958041958\n",
    "# K-value: 9 \t Train Score: 0.9342723004694836\n",
    "# K-value: 11 \t Test Score: 0.9790209790209791\n",
    "# K-value: 11 \t Train Score: 0.9342723004694836\n",
    "# K-value: 13 \t Test Score: 0.972027972027972\n",
    "# K-value: 13 \t Train Score: 0.9248826291079812\n",
    "# K-value: 15 \t Test Score: 0.965034965034965\n",
    "# K-value: 15 \t Train Score: 0.9225352112676056\n",
    "# K-value: 17 \t Test Score: 0.965034965034965\n",
    "# K-value: 17 \t Train Score: 0.9248826291079812\n",
    "# K-value: 19 \t Test Score: 0.965034965034965\n",
    "# K-value: 19 \t Train Score: 0.92018779342723\n",
    "\n",
    "\n",
    "# or if easier to see: \n",
    "#\n",
    "# K-value: 1 \t     Test Score: 0.9300699300699301\n",
    "# K-value: 3 \t     Test Score: 0.9300699300699301\n",
    "# K-value: 5 \t     Test Score: 0.965034965034965\n",
    "# K-value: 7 \t     Test Score: 0.958041958041958\n",
    "# K-value: 9 \t     Test Score: 0.958041958041958\n",
    "# K-value: 11        Test Score: 0.9790209790209791 * \n",
    "# K-value: 13        Test Score: 0.972027972027972\n",
    "# K-value: 15        Test Score: 0.965034965034965\n",
    "# K-value: 17        Test Score: 0.965034965034965\n",
    "# K-value: 19        Test Score: 0.965034965034965\n",
    "# \n",
    "# K-value: 1 \t     Training Score: 1.0 * \n",
    "# K-value: 3 \t     Training Score: 0.9507042253521126\n",
    "# K-value: 5 \t     Training Score: 0.9342723004694836\n",
    "# K-value: 7 \t     Training Score: 0.9366197183098591\n",
    "# K-value: 9 \t     Training Score: 0.9342723004694836\n",
    "# K-value: 11 \t     Training Score: 0.9342723004694836\n",
    "# K-value: 13 \t     Training Score: 0.9248826291079812\n",
    "# K-value: 15 \t     Training Score: 0.9225352112676056\n",
    "# K-value: 17 \t     Training Score: 0.9248826291079812\n",
    "# K-value: 19 \t     Training Score: 0.92018779342723\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "23fa51cf747fbd00ac1d5bc2253c707d",
     "grade": true,
     "grade_id": "cell-e17d6199583d1080",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_eleven()\n",
    "\n",
    "assert isinstance(stu_ans, int), \"Q11: Your function should return an integer. \"\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12: Overfitting  (15 points)\n",
    "\n",
    "A key sign of overfitting is obtaining a training set accuracy that is extremely high (or even perfect), but a test set accuracy that is considerably lower. It is tempting to use a classifier that does so well on the training data it was given, but reality sets in when we try to use this overfit classifier on new test data and we discover it does not in fact generalize well.\n",
    "\n",
    "Using the same set of possible k-NN classifiers and values of $k$ as the previous question (Q11), look for a scenario where overfitting is likely to be happening, by finding the optimal value for $k$ if your goal was to pick the classifier that did best only on the **training set**.  Compute what the resulting test set accuracy would have been, if you had picked that training-set-based value for $k$.\n",
    "\n",
    "Your function should return an (`int`, `float`, `float`) tuple, as follows:\n",
    "\n",
    "`tuple[0]`: the optimal value of $k$ that maximizes *training set* accuracy\n",
    "\n",
    "`tuple[1]`: the corresponding *training set* accuracy for that optimal $k$\n",
    "\n",
    "`tuple[2]`: the corresponding *test set* accuracy that you would have received *if* you had used that optimal $k$.\n",
    "\n",
    "(It is instructive to compare this test set accuracy with the best one you were able to achieve in question 11.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0710d66e6fc7580cab9f50af49180904",
     "grade": false,
     "grade_id": "cell-fa4b5a5c9ec7dd40",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1.0, 0.9300699300699301)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "k_to_training_score_mapper = {}\n",
    "\n",
    "k_to_test_score_mapper     = {}\n",
    "\n",
    "\n",
    "def answer_twelve():\n",
    "    \n",
    "    k_best = None\n",
    "\n",
    "    # --- my code here ---\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = answer_four()\n",
    "    \n",
    "    k_sweep = [num for num in range(20) if num % 2 == 1] \n",
    "    #  this will be:  [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "\n",
    "    for kval in k_sweep:\n",
    "        \n",
    "        knnclf = KNeighborsClassifier(n_neighbors=kval)\n",
    "        # we create an instance of Neighbours Classifier and fit the data\n",
    "        \n",
    "        knnclf.fit(X_train, y_train)\n",
    "        \n",
    "        test_score = knnclf.score(X_test, y_test)\n",
    "        \n",
    "        train_score = knnclf.score(X_train, y_train)\n",
    "        \n",
    "        k_to_training_score_mapper[kval] = train_score\n",
    "        \n",
    "        k_to_test_score_mapper[kval] = test_score\n",
    "        \n",
    "    \n",
    "    \n",
    "    # print(k_to_score_mapper)\n",
    "    # dict: \n",
    "    #  {1: 1.0, 3: 0.9507042253521126, 5: 0.9342723004694836, 7: 0.9366197183098591, \n",
    "    #  9: 0.9342723004694836, 11: 0.9342723004694836, 13: 0.9248826291079812, \n",
    "    #  15: 0.9225352112676056, 17: 0.9248826291079812, 19: 0.92018779342723}\n",
    "        \n",
    "    \n",
    "    #  1. use numbers, it helps \n",
    "    k_best = max(k_to_training_score_mapper, key=lambda kval: k_to_training_score_mapper[kval])\n",
    "    # this is the k for the highest training score value \n",
    "    \n",
    "    #  2. \n",
    "    highest_training_score_for_k_best = max(k_to_training_score_mapper, key=k_to_training_score_mapper.get)\n",
    "    \n",
    "    #  3. \n",
    "    test_score_for_k_best = k_to_test_score_mapper[k_best]\n",
    "    \n",
    "    \n",
    "    # the k value for the best accuracy (training, not test set)\n",
    "    \n",
    "    # python ok way to find max value in dictionary: \n",
    "    #    all_values = a_dictionary.values()\n",
    "    #    max_value = max(all_values)\n",
    "\n",
    "    return (k_best, float(highest_training_score_for_k_best), test_score_for_k_best) \n",
    "    #  tuple[0]: the optimal value of  𝑘  that maximizes training set accuracy (in my case 1)\n",
    "    #  tuple[1]: the corresponding training set accuracy for that optimal 𝑘  (in my case 1.0)\n",
    "    #  tuple[2]: the corresponding test set accuracy that you would have received if you had used that optimal 𝑘 .\n",
    "    \n",
    "    \n",
    "answer_twelve()\n",
    "\n",
    "\n",
    "# this answer makes sense\n",
    "#   - the most overfit would probably be k=1, very tight and complex\n",
    "#   - it also results in a perfect score (training), due to probably memorization \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "81073a47b9cf1997a55d102f6f2c072f",
     "grade": true,
     "grade_id": "cell-9d8ba54a5e282cd7",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests\n",
    "\n",
    "stu_ans = answer_twelve()\n",
    "\n",
    "assert isinstance(stu_ans, tuple), \"Q12: Your function should return a tuple. \"\n",
    "assert len(stu_ans) == 3, \"Q12: The length of your returned tuple should be 3. \"\n",
    "assert isinstance(stu_ans[0], int), \"Q12: Your tuple format should be (*int*, float, float). \"\n",
    "assert isinstance(stu_ans[1], float), \"Q12: Your tuple format should be (int, *float*, float). \"\n",
    "assert isinstance(stu_ans[1], float), \"Q12: Your tuple format should be (int, float, *float*). \"\n",
    "\n",
    "\n",
    "del stu_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from sklearn.neighbors import (NeighborhoodComponentsAnalysis,\n",
    "# ... KNeighborsClassifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  ADD IN A DIRECT PREDICTION \n",
    "#Predict Output\n",
    "# predicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild\n",
    "# print(predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_size=0.3\n",
    "# X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.3) # 70% training and 30% test\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_supervised_learning_v1_assignment1"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
